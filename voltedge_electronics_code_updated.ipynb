{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from scipy.stats import zscore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load Datasets (csv's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers       = pd.read_csv(\"Datasets\\Customers.csv\", \n",
    "                              encoding=\"latin1\")\n",
    "\n",
    "exchange_rates  = pd.read_csv(\"Datasets\\Exchange_Rates.csv\", \n",
    "                              encoding=\"latin1\")\n",
    "\n",
    "products        = pd.read_csv(\"Datasets\\Products.csv\", \n",
    "                              encoding=\"latin1\")\n",
    "\n",
    "sales           = pd.read_csv(\"Datasets\\Sales.csv\",\n",
    "                              encoding=\"latin1\")\n",
    "\n",
    "stores          = pd.read_csv(\"Datasets\\Stores.csv\", \n",
    "                              encoding=\"latin1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns and data types\n",
    "customers.info()\n",
    "\n",
    "# Cleanup: Convert object birthday to date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in customers\n",
    "customers.isnull().sum()\n",
    "\n",
    "# Cleanup: State code has 10 null values. Replace these missing values with their codes based on state names of existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates = no duplicate rows\n",
    "duplicates = customers.duplicated()\n",
    "\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that customer keys are unique = 15266 unique keys = correct\n",
    "customers[\"CustomerKey\"].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers = no measurable columns so no outliers to detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.info()\n",
    "\n",
    "# Convert objects order date and delivery date to date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in sales\n",
    "sales.isnull().sum()\n",
    "\n",
    "# Cleanup: Delivery Date has 49719 null values. Wont be good to exclude all these dates as it forms the majority of the dataset\n",
    "# Find average delivery date based on existing order and delivery dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates = no duplicate rows\n",
    "duplicates = sales.duplicated()\n",
    "\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique order number and line item combo/ duplicate order number- line item combo = no duplicates\n",
    "sales.duplicated(subset=['Order Number', 'Line Item']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outliers: Quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in Quantity column\n",
    "\n",
    "# Data distribution\n",
    "sales['Quantity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data distribution via histogram = skewed to the right\n",
    "sns.histplot(sales['Quantity'], kde=True)\n",
    "plt.title(\"Distribution of Quantity\")\n",
    "plt.xlabel(\"Quantity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data distribution via skewness calculation = 1.12 = right/ positive skew\n",
    "sales['Quantity'].skew()\n",
    "\n",
    "# Interpretation:\n",
    "# 0 = perfectly symmetrical (normal)\n",
    "\n",
    "# 0 to ±0.5 = roughly symmetrical\n",
    "\n",
    "# > +0.5 = right-skewed (positive skew)\n",
    "\n",
    "# < -0.5 = left-skewed (negative skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use IQR to check for outliers since it doesn't rely on normal distribution\n",
    "# There are 1808 outliers for quantity\n",
    "Q1 = sales['Quantity'].quantile(0.25)\n",
    "Q3 = sales['Quantity'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Flag outliers\n",
    "outliers = sales[(sales['Quantity'] < lower_bound) | (sales['Quantity'] > upper_bound)]\n",
    "\n",
    "print(\"Number of outliers:\", len(outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let assess the outliers further to decide how to treat them = no treatment\n",
    "outliers.sort_values(by= \"Quantity\", ascending=False)\n",
    "\n",
    "# 9 and 10 units per order is common for some products (e.g., bulk purchases), won't treat it as an outlier for those products. \n",
    "# In this case, a max of 10 is reasonable and not necessarily an data entry error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3. Exchange Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rates.info()\n",
    "\n",
    "# Convert object date to date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check exchange rate for null values\n",
    "exchange_rates.isnull().sum()\n",
    "\n",
    "# No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows = no duplicates\n",
    "exchange_rates.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Outliers: Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stats\n",
    "exchange_rates['Exchange'].describe()\n",
    "\n",
    "# These numbers are typical of real-world exchange rates between major currencies (e.g., EUR/USD, GBP/USD, CAD/EUR). \n",
    "# Most float between 0.6 and 1.7, which is entirely realistic.\n",
    "# No values are obviously erroneous (e.g., no 0s, 10s, or 100s).\n",
    "# The distribution appears mildly right-skewed, but within reason — \n",
    "# possibly due to weaker currencies (e.g., ZAR, INR) being compared against stronger ones (e.g., USD, EUR).\n",
    "# The standard deviation is low relative to the mean (~23%), suggesting no major volatility spikes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection = no outliers\n",
    "Q1 = exchange_rates['Exchange'].quantile(0.25)\n",
    "Q3 = exchange_rates['Exchange'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Prints exchange rates that are below the lower bound or above the upper bound\n",
    "outliers = exchange_rates[(exchange_rates['Exchange'] < lower_bound) | (exchange_rates['Exchange'] > upper_bound)]\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4. Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.info()\n",
    "\n",
    "# Remove the dollar symbol from objects unit cost usd and unit price usd and convert to float type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check products for null values\n",
    "products.isnull().sum()\n",
    "\n",
    "# No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique product key = True\n",
    "products['ProductKey'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if product name is unique = True\n",
    "products['Product Name'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows = no duplicate rows\n",
    "products.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Outliers: Unit Cost and Unit Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Unit Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the dollar symbol and commas from objects unit cost usd and unit price usd and convert to float type\n",
    "\n",
    "products[\"Unit Cost USD\"]   = products[\"Unit Cost USD\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(\"float\")\n",
    "\n",
    "products[\"Unit Price USD\"]  = products[\"Unit Price USD\"].str.replace(\"$\", \"\").str.replace(\",\",\"\").astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All categories\n",
    "products.value_counts('Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats for each category\n",
    "products.groupby('Category')['Unit Cost USD'].describe()\n",
    "\n",
    "# Home Appliances\n",
    "# Outliers: This category could include expensive appliances like refrigerators, washers, or dryers.\n",
    "# Treatment: No action needed. The maximum value is reasonable for high-end or luxury appliances. \n",
    "# Leave the outliers as they are. No data entry issues.\n",
    "\n",
    "# Computers\n",
    "# Outliers: This category can include high-end computers like gaming laptops or workstations, which can be expensive.\n",
    "# Treatment: No action needed. The maximum value appears to be reasonable for premium or professional computers. \n",
    "# You could verify the nature of these items, but generally, no change is required.\n",
    "\n",
    "# Cameras and Camcorders\n",
    "# Outliers: Prices up to 536.74 USD are typical for high-end cameras.\n",
    "# Treatment: No action needed. The outliers are likely legitimate high-end products. \n",
    "# You can leave them as they are, but it would be beneficial to document that they represent premium or professional-grade items.\n",
    "\n",
    "# TV & Video\n",
    "# Outliers: This category includes high-end televisions and video equipment, so the prices up to 960.82 are reasonable.\n",
    "# Treatment: No action needed. The outliers are likely valid and represent high-end products. \n",
    "# Verify the nature of the products if needed, but generally, no action is required.\n",
    "\n",
    "# Games & Toys (have high outliers so will assess them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying outliers in Games and Toys category\n",
    "games_and_toys = products[products['Category'] == 'Games and Toys']\n",
    "q1 = games_and_toys['Unit Cost USD'].quantile(0.25)\n",
    "q3 = games_and_toys['Unit Cost USD'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Set display option to show more characters in string columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "outliers_games_and_toys = games_and_toys[(games_and_toys['Unit Cost USD'] < lower_bound) | (games_and_toys['Unit Cost USD'] > upper_bound)]\n",
    "outliers_games_and_toys[['Product Name', 'Unit Cost USD', 'Subcategory']]\n",
    "\n",
    "# Price Range of Downloadable Games: Download games typically range from $5 to $50 USD (depending on the type of game and platform). \n",
    "# Prices for premium games or special editions could go higher, \n",
    "# but $198.39 seems unusually high for a standard downloadable game, which may suggest an error or anomaly in the data.\n",
    "# Compare with Median: You found that the median price for the \"Download Games\" subcategory is $21.92. \n",
    "# This suggests that most games in this category fall within a much lower price range, making $198.39 an outlier.\n",
    "# Treatment: Will replace the value with a median price for download games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all download games\n",
    "products[(products['Subcategory'] == 'Download Games') & (products['Unit Cost USD'] == 198.39)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Treatment\n",
    "\n",
    "# Filter the data for \"Download Games\"\n",
    "d_games = products[products['Subcategory'] == 'Download Games']\n",
    "d_games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Download Games\n",
    "products[products['Subcategory'] == 'Download Games']\n",
    "\n",
    "# Find the median of the \"Unit Cost USD\" for Download Games = 21.92\n",
    "median_cost = d_games['Unit Cost USD'].median()\n",
    "\n",
    "# Loop through each row in the DataFrame and replace outlier with median if condition met\n",
    "for index, row in products.iterrows():\n",
    "    if row['Subcategory'] == 'Download Games' and row['Unit Cost USD'] == 198.39:\n",
    "        products.at[index, 'Unit Cost USD'] = median_cost\n",
    "\n",
    "# Verify the change = Yes, new unit cost is $21.92\n",
    "products[products['Product Name'] == 'MGS Age of Empires Expansion: The Rise of Rome X900']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Outliers: Unit Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stats based on category for more accuracy\n",
    "products.groupby('Category')['Unit Price USD'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the category stats that need outlier detection\n",
    "# Since this is not a normal distribution I will use IQR method\n",
    "\n",
    "# Audio Distribution = 0.39 = slightly right skewed but close to normal\n",
    "audio = products[products[\"Category\"] == \"Audio\"]\n",
    "skew = audio[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"Therefore, to be more robust, I will use the IQR method.\")\n",
    "print()\n",
    "\n",
    "#IQR = 132.5\n",
    "Q1 = 67.400\n",
    "Q3 = 199.9000\n",
    "IQR = Q3 - Q1\n",
    "print(f\"IQR = {IQR}\")\n",
    "\n",
    "# Upper Bound = 398.65\n",
    "upper = Q3 + 1.5 * IQR\n",
    "print(f\"Upper Bound = {upper}\")\n",
    "\n",
    "# Lower Bound = -131.35\n",
    "lower = Q1 - 1.5 * IQR\n",
    "print(f\"Lower bound = {lower}\")\n",
    "\n",
    "# Filter for outliers = no outliers\n",
    "audio[(audio[\"Unit Price USD\"] < lower) | (audio[\"Unit Price USD\"] > upper)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cameras and Camcorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cameras Distribution Skew = 1.63 = highly positively skewed\n",
    "cameras = products[products[\"Category\"] == \"Cameras and camcorders\"]\n",
    "skew = cameras[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print()\n",
    "\n",
    "# Calculate IQR = 397\n",
    "Q1 = 176\n",
    "Q3 = 573\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(f\"IQR = {IQR}\")\n",
    "\n",
    "# Lower Bound = -419.5\n",
    "lower = Q1 - 1.5 * IQR\n",
    "print(f\"Lower bound = {lower}\")\n",
    "\n",
    "# Upper Bound = 595.5\n",
    "upper = Q3 = 1.5 * IQR\n",
    "print(f\"Upper bound = {upper}\")\n",
    "\n",
    "# Filter for the Upper Outliers\n",
    "cam_outliers = cameras[(cameras[\"Unit Price USD\"] < lower) | (cameras[\"Unit Price USD\"] > upper)]\n",
    "cam_outliers.sort_values(by=\"Unit Price USD\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asessing Cameras and Camcorders Outliers\n",
    "# Brand Name Counts\n",
    "outlier_cam_count = cam_outliers[\"Brand\"].value_counts()\n",
    "\n",
    "# All camera brand counts\n",
    "normal_cam_count = cameras.value_counts(\"Brand\")\n",
    "\n",
    "print(f\"All Cameras: {normal_cam_count}\")\n",
    "\n",
    "print()\n",
    "print(f\"Outlier Cameras: {outlier_cam_count}\")\n",
    "\n",
    "# It is determined that These are luxury brand cameras so the outliers for Fabrikan will have to be calculated based on the brand name alone\n",
    "# As for the other 2, I will examine them manually to determine how to treat them. Will probably be seen as entry errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining Contoso Outliers\n",
    "contoso_outliers = cam_outliers[cam_outliers[\"Brand\"] == \"Contoso\"]\n",
    "\n",
    "print(\"Contoso outliers table:\")\n",
    "contoso_outliers\n",
    "\n",
    "# Stakeholders were consulted to determine whether or not the 7 Contoso Camera Outliers were data entry mistakes or accurate prices and they were accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for only Contoso Cameras\n",
    "contoso_cameras_all = products[(products[\"Brand\"] == \"Contoso\") & (products[\"Category\"] == \"Cameras and camcorders\")].sort_values(by=\"Unit Price USD\", ascending=False)\n",
    "\n",
    "# Distribution type for Contoso Cameras skewness = 0.85 which is right-skewed\n",
    "skew = contoso_cameras_all['Unit Price USD'].skew()\n",
    "print(f\"Skewness = {skew}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use IQR Method to find brand-specific outliers for Contoso cameras\n",
    "Q1 = contoso_cameras_all[\"Unit Price USD\"].quantile(0.25)\n",
    "Q3 = contoso_cameras_all[\"Unit Price USD\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(f\"IQR = {IQR}\")\n",
    "print()\n",
    "\n",
    "# Lower Bound\n",
    "lower = Q1 - 1.5 * IQR\n",
    "print(f\"Lower bound = {lower}\")\n",
    "\n",
    "# Upper Bound\n",
    "upper = Q3 + 1.5 * IQR\n",
    "print(f\"Upper bound = {upper}\")\n",
    "print()\n",
    "\n",
    "# Are there any outliers?\n",
    "print(f\"There are no outliers for Contoso cameras\")\n",
    "\n",
    "# Filter for outliers\n",
    "contoso_cameras_all[(contoso_cameras_all[\"Unit Price USD\"] < lower) | (contoso_cameras_all[\"Unit Price USD\"] > upper)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for A. Datum camera brand\n",
    "adatum = cameras[cameras[\"Brand\"] == \"A. Datum\"]\n",
    "\n",
    "# Analysing A. Datum Cameras\n",
    "skew = adatum[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"Therefore the data distribution is right-skewed and IQR method will be applied.\")\n",
    "\n",
    "# IQR\n",
    "Q1 = adatum[\"Unit Price USD\"].quantile(0.25)\n",
    "Q3 = adatum[\"Unit Price USD\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print()\n",
    "print(f\"IQR = {IQR}\")\n",
    "\n",
    "# Lower Bound\n",
    "lower = Q1 - 1.5 * IQR\n",
    "print(f\"Lower Bound = {lower}\")\n",
    "\n",
    "# Upper Bound\n",
    "upper = Q3 + 1.5 * IQR\n",
    "print(f\"Upper Bound = {upper}\")\n",
    "print()\n",
    "\n",
    "# Filter for outliers\n",
    "adatum_cameras_outliers = adatum[(adatum[\"Unit Price USD\"] < lower) | (adatum[\"Unit Price USD\"] > upper)]\n",
    "adatum_cameras_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment\n",
    "print(\"After consulting the stakeholders to find out if these Unit Prices are accurate,\")\n",
    "print(\"it was discovered that x358 versions of A. Datum cameras have more advanced and professional features.\")\n",
    "print(\"For the $627.0 cameras, these 5 models of camera were all special edition camras whose prices were reflected accurately.\")\n",
    "print(\"and the stakeholder advised me to keep all values within the dataset to reflect accuracy\")\n",
    "\n",
    "# Investigating the upper outliers for A Datum Cameras by filtering for the outliers\n",
    "adatum_cameras_outliers.sort_values(by=\"Unit Price USD\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing Fabrikam Cameras \n",
    "fabrikam_cameras = products[(products[\"Brand\"] == \"Fabrikam\") & (products[\"Category\"] == \"Cameras and camcorders\")]\n",
    "\n",
    "# Data Distribution = 0.89\n",
    "skew = fabrikam_cameras[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"Therefore, this is a right-skewed distribution and IQR method will apply.\")\n",
    "\n",
    "# Calculate IQR\n",
    "Q1 = fabrikam_cameras[\"Unit Price USD\"].quantile(0.25)\n",
    "Q3 = fabrikam_cameras[\"Unit Price USD\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print()\n",
    "print(f\"IQR = {IQR}\")\n",
    "\n",
    "# Lower Bound\n",
    "lower = Q1 - 1.5 * IQR\n",
    "print(f\"Lower Bound = {lower}\")\n",
    "\n",
    "# Upper Bound\n",
    "upper = Q3 + 1.5 * IQR\n",
    "print(f\"Upper Bound = {upper}\")\n",
    "\n",
    "# Treatment\n",
    "print(\"There are no outliers, therefore, no treatment to be applied.\")\n",
    "fabrikam_cameras[(fabrikam_cameras[\"Unit Price USD\"] < lower ) | (fabrikam_cameras[\"Unit Price USD\"] > upper)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellphones\n",
    "cellphones = products[products[\"Category\"] == \"Cell phones\"]\n",
    "\n",
    "# Skewness = 0.31\n",
    "skew = cellphones[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"Therefore, the data is slightly positive-skewed. So use IQR method.\")\n",
    "print()\n",
    "\n",
    "# IQR\n",
    "Q1 = cellphones[\"Unit Price USD\"].quantile(0.25)\n",
    "Q3 = cellphones[\"Unit Price USD\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Lower Bound\n",
    "lower = Q1 - 1.5 * IQR\n",
    "print(f\"Lower Bound = {lower}\")\n",
    "\n",
    "# Upper Bound\n",
    "upper = Q3 + 1.5 * IQR\n",
    "print(f\"Upper Bound = {upper}\")\n",
    "print()\n",
    "\n",
    "# Treatment\n",
    "print(\"Treatment:\")\n",
    "print(f\"There are no outliers for cellphones.\")\n",
    "\n",
    "# Filter for outliers\n",
    "cellphones[(cellphones[\"Unit Price USD\"] < lower) | (cellphones[\"Unit Price USD\"] > upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computers Outlier Detection\n",
    "computers = products[products[\"Category\"] == \"Computers\"]\n",
    "\n",
    "# Skewness = 2.89\n",
    "skew = computers[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"Therefore the data is highly skewed to the right. Log + IQR methods will be applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to avoid modifying the original\n",
    "df = computers.copy()\n",
    "\n",
    "# Add 1 to avoid log(0)\n",
    "df['log_price'] = np.log(df['Unit Price USD'] + 1)\n",
    "\n",
    "# Compute IQR\n",
    "Q1 = df['log_price'].quantile(0.25)\n",
    "Q3 = df['log_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Flag outliers in log scale\n",
    "log_outliers = df[(df['log_price'] < lower_bound) | (df['log_price'] > upper_bound)]\n",
    "\n",
    "# Note\n",
    "print(\"Only 4 lower outliers exist within the computers category for the computers Accessories category and these are all the same version of E600 USB Data Cable\")\n",
    "\n",
    "log_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Treatment\n",
    "print(\"These 4 items will be kept in the data as this is not a data entry issue. Not unusual for USB cables to cost $0.95. However, it will be noted in the final report\")\n",
    "print(\"that cheaper accessory items are being lumped in with pricier items like laptops/desktops.\")\n",
    "\n",
    "# Computer Categories\n",
    "computers[\"Subcategory\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Games and Toys\n",
    "games = products[products[\"Category\"] == \"Games and Toys\"]\n",
    "\n",
    "# Skewness = 7.77\n",
    "skew = games[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewnesss = {skew}\")\n",
    "print(\"Therefore this data is highly/ extremelly right-skewed and I will use the log + IQR method to identify outliers\")\n",
    "\n",
    "# Log \n",
    "df = games.copy()\n",
    "df['log_price'] = np.log(df[\"Unit Price USD\"] + 1)\n",
    "\n",
    "# Compute IQR\n",
    "Q1 = df['log_price'].quantile(0.25)\n",
    "Q3 = df['log_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Flag outliers in log scale\n",
    "log_outliers = df[(df['log_price'] < lower_bound) | (df['log_price'] > upper_bound)]\n",
    "\n",
    "log_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Games and Toys Treatment\n",
    "print(\"Just as I replaced the unit cost with the median cost for Download Games, I will replace the unit price with the median unit price for Download Games.\")\n",
    "\n",
    "# Median\n",
    "download = products[products[\"Subcategory\"] == \"Download Games\"]\n",
    "\n",
    "price_median = download[\"Unit Price USD\"].median()\n",
    "\n",
    "print(f\"Price Median for Download Games = ${price_median}\")\n",
    "\n",
    "# Loop through each row in the DataFrame and replace outlier with median if condition met\n",
    "for index, row in products.iterrows():\n",
    "    if row['Subcategory'] == 'Download Games' and row['Unit Price USD'] == 598.8:\n",
    "        products.at[index, 'Unit Price USD'] = price_median\n",
    "\n",
    "# Verify the change = Yes, new unit cost is $21.92\n",
    "products[products['Product Name'] == 'MGS Age of Empires Expansion: The Rise of Rome X900']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home Appliances\n",
    "appliances = products[products[\"Category\"] == \"Home Appliances\"]\n",
    "\n",
    "# Skewness = 2.15\n",
    "skew = appliances[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"Data is highly right-skewed. Therefore, I will use the Log + IQR method.\")\n",
    "\n",
    "# Log\n",
    "df = appliances.copy()\n",
    "df[\"log_price\"] = np.log(df[\"Unit Price USD\"] + 1)\n",
    "\n",
    "# Compute IQR\n",
    "Q1 = df['log_price'].quantile(0.25)\n",
    "Q3 = df['log_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Flag outliers in log scale\n",
    "log_outliers = df[(df['log_price'] < lower_bound) | (df['log_price'] > upper_bound)]\n",
    "\n",
    "log_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment \n",
    "print(\"Since the 4 low outliers for Home Appliances are all Fans, I decided to filter for fans and investigate their prices.\")\n",
    "print(\"It was noted that there are various types of fans ranging from $4.99 to $400.00 but these fans in particular are dual ball bearing case fans.\")\n",
    "print(\"There is no data entry error when it comes to the Unit Price but case fans are Computer Accessories and not Home Appliances and should be recategorised.\")\n",
    "\n",
    "\n",
    "# Checking Fans in general\n",
    "appliances[appliances[\"Subcategory\"] == \"Fans\"].sort_values(by=\"Unit Price USD\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying ALL Case Fans Under Home Appliances\n",
    "case_fans = (\n",
    "    products['Product Name'].str.contains(\"case fan\", case=False, na=False) &\n",
    "    (products['Category'] == \"Home Appliances\")\n",
    ")\n",
    "\n",
    "case_fans_to_fix = products[case_fans]\n",
    "\n",
    "print(\"This is the list of ALL case fans:\")\n",
    "case_fans_to_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change case fans to computer accessories\n",
    "products.loc[case_fans, 'Category'] = \"Computers\"\n",
    "products.loc[case_fans, 'Subcategory'] = \"Computer Accessories\"\n",
    "products.loc[case_fans, 'SubcategoryKey'] = 308\n",
    "products.loc[case_fans, 'CategoryKey'] = 3\n",
    "\n",
    "# Verify the change\n",
    "products[products['Product Name'].str.contains(\"case fan\", case=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for: Music, Movies and Audio Books\n",
    "music = products[products['Category'] == \"Music, Movies and Audio Books\"]\n",
    "\n",
    "# Skewness = 0.59\n",
    "skew = music[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"The data distribution is mildly right-skewed. Therefore, I will use the IQR method, although z-score would also be acceptable but IQR is more robust.\")\n",
    "\n",
    "# IQR\n",
    "Q1 = music[\"Unit Price USD\"].quantile(0.25)\n",
    "Q3 = music[\"Unit Price USD\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print()\n",
    "\n",
    "# Lower Bound\n",
    "lower = Q1 - 1.5 * IQR\n",
    "print(f\"Lower Bound = {lower}\")\n",
    "\n",
    "# Upper Bound\n",
    "upper = Q3 + 1.5 * IQR\n",
    "print(f\"Upper Bound = {upper}\")\n",
    "\n",
    "# Note\n",
    "print()\n",
    "print(\"Note:\")\n",
    "print(\"There are no outliers so no treatment required.\")\n",
    "\n",
    "# Outliers\n",
    "music[(music[\"Unit Price USD\"] < lower) | (music[\"Unit Price USD\"] > upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for: TV and Video\n",
    "tv = products[products[\"Category\"] == \"TV and Video\"]\n",
    "\n",
    "# Evaluate Skewness = 3.18\n",
    "skew = tv[\"Unit Price USD\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"The data is heavily right-skewed. Therefore, I will use the Log + IQR method.\")\n",
    "\n",
    "# Log\n",
    "df = tv.copy()\n",
    "df[\"log_price\"] = np.log(df[\"Unit Price USD\"] + 1)\n",
    "\n",
    "# IQR\n",
    "Q1 = df[\"log_price\"].quantile(0.25)\n",
    "Q3 = df[\"log_price\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print()\n",
    "\n",
    "# Lower Bound\n",
    "lower = Q1 - 1.5 * IQR\n",
    "print(f\"Lower Bound =  {lower}\")\n",
    "\n",
    "# Upper Bound\n",
    "upper = Q3 + 1.5 * IQR\n",
    "print(f\"Upper Bound = {upper}\")\n",
    "\n",
    "# Isolate the Outliers\n",
    "df_outliers = df[(df[\"log_price\"] < lower) | (df[\"log_price\"] > upper)].sort_values(by=\"Unit Price USD\", ascending=False)\n",
    "df_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier counts for different subcategories for audio\n",
    "df_outliers[\"Subcategory\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment of TV Outliers\n",
    "print(\"Because these are valid prices for these sizes of TV's and the DVDs are limited edition box sets and there are no data entry errors here, \") \n",
    "print(\"I will keep these outliers in the dataset to reflect accuracy for unit prices.\")\n",
    "print()\n",
    "print(\"I will also mention this in my final report and that DVDs from TV and Video section are lumped in with subcategories like Televisions, under assumptions and caveats section for transparency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5. Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.info()\n",
    "\n",
    "# Convert object open date to date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stores for null values\n",
    "stores.isnull().sum()\n",
    "\n",
    "# Cleanup: Square meters has 1 null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the Store Keys Unique \n",
    "stores[\"StoreKey\"].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Rows = 0\n",
    "stores.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers: Square Meters\n",
    "skew = stores[\"Square Meters\"].skew()\n",
    "print(f\"Skewness = {skew}\")\n",
    "print(\"Since the skewness lies close to -0.5. This is slightly left-skewed but I can apply z-score method as it is close to a normal distribution.\")\n",
    "\n",
    "# Note\n",
    "print()\n",
    "print(\"There are no outliers for square meters.\")\n",
    "\n",
    "# Z Score\n",
    "stores['zscore'] = zscore(stores['Square Meters'])\n",
    "outliers = stores[(stores['zscore'].abs() > 2.5)]  \n",
    "\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1. Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object birthday to date type\n",
    "customers.Birthday = pd.to_datetime(customers.Birthday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Code has 10 null values: Replace these missing values with their codes based on state names and codes of existing data\n",
    "\n",
    "# Step 1: Create a mapping of state_name to state_code from non-missing values, set index to State and set State Code as values, convert to dictionary\n",
    "state_mapping = customers.dropna(subset=[\"State Code\"]).set_index(\"State\")[\"State Code\"].to_dict()\n",
    "\n",
    "# Step 2: Fill missing State Code using the mapping\n",
    "customers[\"State Code\"] = customers[\"State Code\"].fillna(customers[\"State\"].map(state_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since mapping didn't work, check the names of missing value states: All of the missing codes are related to the State of Napoli in Italy\n",
    "customers[customers[\"State Code\"].isnull()]\n",
    "\n",
    "# Replace null values with my own code NAP for Napoli. Check if code already exists first\n",
    "customers[customers[\"State Code\"].str.contains(\"NAP\",na=False)]\n",
    "\n",
    "# Replacing all null values with NAP\n",
    "customers[\"State Code\"] = customers[\"State Code\"].fillna(\"NAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert objects order date and delivery date to date type\n",
    "sales[\"Order Date\"]     = pd.to_datetime(sales[\"Order Date\"])\n",
    "\n",
    "sales[\"Delivery Date\"]  = pd.to_datetime(sales[\"Delivery Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delivery Date has 49719 null values. Find delivery time for each row\n",
    "sales[\"Delivery Time\"]  = (sales[\"Delivery Date\"] - sales[\"Order Date\"])\n",
    "\n",
    "# Find the average delivery time based on store: 4 days and 12 hours but only data for StoreKey 0 was available, all other stores had nulls\n",
    "average_delivery_time   = sales.groupby(\"StoreKey\")[\"Delivery Time\"].mean().dropna()\n",
    "\n",
    "# Extract the value for number of days from the store key 0\n",
    "average_days = average_delivery_time.iloc[0]\n",
    "\n",
    "# Replace missing delivery dates by adding average days to each order date where the delivery date is missing\n",
    "sales[\"Delivery Date\"] = sales[\"Delivery Date\"].fillna(sales[\"Order Date\"] + average_days)\n",
    "\n",
    "# Replace missing values for Delivery time(the column I created which will be Nat for missing Delivery Date Values) with the average days\n",
    "sales[\"Delivery Time\"] = sales[\"Delivery Time\"].fillna(average_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When I got to the end of cleaning up the stores table, I realised only store 0 had delivery dates because its an online store\n",
    "\n",
    "# Assuming all other stores with locations are physical and that they don't deliver, hence null values, I'll revert the changes to delivery dates\n",
    "sales.loc[sales[\"StoreKey\"] != 0, \"Delivery Date\"] = pd.NaT\n",
    "\n",
    "# Also drop delivery time column that I calculate for physical stores\n",
    "sales.loc[sales[\"StoreKey\"] != 0, \"Delivery Time\"] = pd.NaT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3. Exchange Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object Date to date type\n",
    "exchange_rates.Date = pd.to_datetime(exchange_rates.Date)\n",
    "\n",
    "# No null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4. Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treated unit cost and unit price strings in previous section (removed dollar sign and converted to float)\n",
    "\n",
    "# No null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5. Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object open date to date type\n",
    "stores[\"Open Date\"] = pd.to_datetime(stores[\"Open Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: Square meters has 1 null value\n",
    "# Check the null value row: through this I discovered StoreKey 0 is missing square meters because its an online store\n",
    "stores[stores[\"Square Meters\"].isnull()]\n",
    "\n",
    "# So I replace the null value with a 0 for 0m^2\n",
    "stores.loc[stores[\"StoreKey\"] == 0, \"Square Meters\"] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1. Join Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join Customers to Sales\n",
    "sales_merged = sales.merge(customers, on=\"CustomerKey\", how=\"left\")\n",
    "\n",
    "# Left Join Products to Sales Merged\n",
    "sales_merged = sales_merged.merge(products, on=\"ProductKey\", how=\"left\")\n",
    "\n",
    "# Left Join Stores to Sales Merged\n",
    "sales_merged = sales_merged.merge(stores, on=\"StoreKey\", how=\"left\")\n",
    "\n",
    "# Left Join Exchange Rates to Sales Merged\n",
    "sales_merged = sales_merged.merge(exchange_rates, left_on=[\"Currency Code\", \"Order Date\"], right_on=[\"Currency\", \"Date\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2. Add Order Month, Order Year, Revenue column, Customer Age column, Store Age column and Store Type column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order Month\n",
    "sales_merged[\"Order Month\"] = sales_merged[\"Order Date\"].dt.strftime('%b')\n",
    "\n",
    "# Order Year\n",
    "sales_merged[\"Order Year\"] = sales_merged[\"Order Date\"].dt.year\n",
    "\n",
    "# Revenue: Multiply Quatity column with Unit Price USD column\n",
    "sales_merged[\"Revenue\"] = sales_merged[\"Quantity\"] * sales_merged[\"Unit Price USD\"]\n",
    "\n",
    "# Customer Age: To obtain customer age at the point of order, birth date is subtracted from order date, \n",
    "# converted from timedelta to days and divided by a year using floor division to obtain the age in years rounded down\n",
    "sales_merged[\"Customer Age\"] = (sales_merged[\"Order Date\"] - sales_merged[\"Birthday\"]).dt.days // 365\n",
    "\n",
    "# Store Age: To obtain store age at the point of order, open date is subtracted from order date,\n",
    "# converted from timedelta to days and divided by a year using floor division to obtain the age in years rounded down\n",
    "sales_merged[\"Store Age\"] = (sales_merged[\"Order Date\"] - sales_merged[\"Open Date\"]).dt.days // 365\n",
    "\n",
    "# Store Type (Online vs Physical)\n",
    "sales_merged[\"Store Type\"] = sales_merged[\"Country_y\"].apply(lambda x: \"Online\" if x == \"Online\" else \"Physical\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3. Change Column Headings: \n",
    "- **State_x** as Customer State\n",
    "- **State_y** as Store State \n",
    "- **Country_x** as Customer Country\n",
    "- **Country_y** as Store Country \n",
    "- **Date** as Exchange Rate Date\n",
    "- **CustomerKey** as Customer Key\n",
    "- **StoreKey** as Store Key\n",
    "- **ProductKey** as Product Key\n",
    "- **CategoryKey** as Category Key\n",
    "- **SubcategoryKey** as Subcategory Key\n",
    "- **Name** to Customer Name\n",
    "- **City** to Customer City\n",
    "- **State Code** to Customer State Code\n",
    "- **Zip Code** to Customer Zip Code\n",
    "- **Continent** to Customer Continent\n",
    "- **Birthday** as Customer Birthday\n",
    "- **Open Date** to Store Open Date\n",
    "- **Exchange** to Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Headings\n",
    "sales_merged = sales_merged.rename(columns={\"State_x\" : \"Customer State\", \"State_y\": \"Store State\", \"Country_x\": \"Customer Country\", \"Country_y\": \"Store Country\", \n",
    "                                            \"Date\": \"Exchange Rate Date\", \"CustomerKey\": \"Customer Key\", \"StoreKey\": \"Store Key\", \"ProductKey\": \"Product Key\", \n",
    "                                            \"CategoryKey\": \"Category Key\", \"SubcategoryKey\": \"Subcategory Key\", \"Name\": \"Customer Name\", \"City\": \"Customer City\", \n",
    "                                            \"State Code\": \"Customer State Code\", \"Zip Code\": \"Customer Zip Code\", \"Continent\": \"Customer Continent\", \"Birthday\": \"Customer Birthday\",\n",
    "                                            \"Open Date\": \"Store Open Date\", \"Exchange\": \"Exchange Rate\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4. Remove Duplicate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Currency Code column as the information duplicates itself in Currency column\n",
    "sales_merged.drop(columns=[\"Currency Code\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5. Rearrange Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_merged = sales_merged[[\"Order Number\", \"Line Item\", \"Order Date\", \"Order Month\", \"Order Year\", \"Delivery Date\", \"Delivery Time\", \"Quantity\", \"Unit Price USD\", \"Unit Cost USD\", \"Revenue\", \n",
    "                             \"Customer Key\", \"Customer Name\", \"Gender\", \"Customer Birthday\", \"Customer Age\", \"Customer City\", \"Customer State\", \"Customer State Code\", \n",
    "                             \"Customer Zip Code\", \"Customer Country\", \"Customer Continent\", \"Product Key\", \"Product Name\", \"Brand\", \"Color\", \"Category Key\", \"Category\", \n",
    "                             \"Subcategory Key\", \"Subcategory\", \"Store Key\", \"Store Country\", \"Store State\", \"Square Meters\", \"Store Open Date\", \"Store Age\", \"Store Type\", \"Currency\", \n",
    "                             \"Exchange Rate Date\", \"Exchange Rate\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Aggregation and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1. Sales Performance & Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.1.1 Revenue By Category Overall (SNS LINEPLOT VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "# % Revenue by Category (all 5 years)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "# Adjust figure size\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "# Aggregate Revenue Data\n",
    "revenue_by_category = sales_merged.pivot_table(index=\"Order Date\", columns=\"Category\", values=\"Revenue\", aggfunc=\"sum\")\n",
    "\n",
    "# Get Monthly level data from order dates for plotting\n",
    "revenue_by_category = revenue_by_category.resample(\"ME\").sum()\n",
    "\n",
    "#Adjust figure size\n",
    "plt.figure(figsize=(30,12))\n",
    "# Ensure Abbreviated Months are Shown on plot\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())  # Show major tick marks for years\n",
    "plt.gca().xaxis.set_minor_locator(mdates.MonthLocator(interval=1))  # Minor ticks for months\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))  # Show Year at major ticks\n",
    "plt.gca().xaxis.set_minor_formatter(mdates.DateFormatter(\"%b\"))  # Show Month at minor ticks\n",
    "\n",
    "# Add axv lines to separate years\n",
    "years = revenue_by_category.index.year.unique()  # Get unique years in the data\n",
    "for year in years[1:]:  # Skip first year to avoid unnecessary line at start\n",
    "    year_start = pd.Timestamp(year=year, month=1, day=1)  # Start of each year\n",
    "    plt.gca().axvline(x=year_start, color=\"grey\", linestyle=\"dotted\", linewidth=1)  # Dotted separator for years\n",
    "\n",
    "# Plot the Line Graph. Name Lineplot as ax to format axis\n",
    "ax = sns.lineplot(data=revenue_by_category, dashes=False, palette=\"husl\", linewidth=2)\n",
    "\n",
    "# Formatting the Chart\n",
    "#-----------------------\n",
    "# Increase legend size\n",
    "legend = ax.legend(fontsize=25, title=\"Product Category\", title_fontsize=30)\n",
    "\n",
    "# Left-align the legend title\n",
    "legend._legend_box.align = \"left\"\n",
    "\n",
    "# Format y-axis as currency\n",
    "ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'${x/1000:.0f}k'))\n",
    "\n",
    "# Increase Y-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "# Ensure Rotation Applies to Both Major(years) & Minor(months) Ticks\n",
    "ax.tick_params(axis='x', which='major', labelsize=20, rotation=90, pad=20)  # Rotate years\n",
    "ax.tick_params(axis='x', which='minor', labelsize=16, rotation=90, pad=5)\n",
    "\n",
    "# Remove the top and right border (spines)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "plt.title(\"Comparing Revenue Growth by Product Category (2016-2020)\", fontsize=45, pad=30)\n",
    "plt.xlabel(\"\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.1.1 Revenue By Category Overall (PLOTLY LINEPLOT VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# % Revenue by Category (2016-2020)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# Aggregate Revenue Data Using Pivot Table\n",
    "revenue_by_category = sales_merged.pivot_table(\n",
    "    index=\"Order Date\", \n",
    "    columns=\"Category\", \n",
    "    values=\"Revenue\", \n",
    "    aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "# Resample Data to Monthly Level for Smoother Trends\n",
    "revenue_by_category = revenue_by_category.resample(\"ME\").sum()\n",
    "\n",
    "# Use the \"Greens\" Palette from Plotly\n",
    "greens_palette = px.colors.sequential.Greens  \n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Create Interactive Line Graph\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Each Product Category as a Separate Line\n",
    "for i, category in enumerate(revenue_by_category.columns):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=revenue_by_category.index, \n",
    "        y=revenue_by_category[category], \n",
    "        mode=\"lines\", \n",
    "        name=category,  \n",
    "        line=dict(color=greens_palette[i % len(greens_palette)], width=2)  # Cycle through green shades\n",
    "    ))\n",
    "\n",
    "# Add Vertical Year Separators (Replacing `axvline()`)\n",
    "years = revenue_by_category.index.year.unique()\n",
    "for year in years[1:]:  # Skip first year to avoid unnecessary line at start\n",
    "    fig.add_shape(\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0=pd.Timestamp(year=year, month=1, day=1),\n",
    "            x1=pd.Timestamp(year=year, month=1, day=1),\n",
    "            y0=0, \n",
    "            y1=1,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            line=dict(color=\"grey\", width=0.5, dash=\"dot\")  # Light dotted separator for years\n",
    "        )\n",
    "    )\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Format Axes, Labels, and Chart Styling\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Comparing Revenue Growth by Product Category (2016-2020)\",\n",
    "    title_font=dict(size=30),\n",
    "    \n",
    "    xaxis=dict(\n",
    "        title=\"\",  # Updated for clarity\n",
    "        tickformat=\"%Y\",  # Show only the year (e.g., 2016, 2017, 2018)\n",
    "        dtick=\"M12\",  # Ensure one tick per year\n",
    "        tickmode=\"linear\",  # Ensure consistent spacing\n",
    "        tickangle=0,  # No rotation needed for years\n",
    "        showgrid=False\n",
    "    ),\n",
    "    \n",
    "    yaxis=dict(\n",
    "        title=\"\",  # Added for clarity\n",
    "        tickprefix=\"$\",  # Format as currency\n",
    "        tickformat=\",.0f\",  # Use commas for thousands (e.g., $10,000)\n",
    "        showgrid=True\n",
    "    ),\n",
    "\n",
    "    legend=dict(\n",
    "        title=\"Product Category\",\n",
    "        font=dict(size=18),\n",
    "        x=1, y=1  # Move legend to the right\n",
    "    ),\n",
    "\n",
    "    plot_bgcolor=\"white\",  # Clean background for a professional look\n",
    "    height=500,\n",
    "    width=1400\n",
    ")\n",
    "\n",
    "# Show the interactive Plotly graph\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.1.2. Online VS Physical Revenue (SNS CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "# Online vs Physical Stores Revenue\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create subplot 2x1\n",
    "fig, ax = plt.subplots(2,1, figsize=(30,15))\n",
    "\n",
    "# Line Graph\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Table\n",
    "rev_store_type = sales_merged.pivot_table(index=\"Order Date\", columns=\"Store Type\", values=\"Revenue\", aggfunc=\"mean\")\n",
    "\n",
    "# Get Monthly level data from order dates for plotting\n",
    "rev_store_type = rev_store_type.resample(\"ME\").mean()\n",
    "\n",
    "# Ensure Abbreviated Months are Shown on plot\n",
    "ax[0].xaxis.set_major_locator(mdates.YearLocator())  # Show major tick marks for years\n",
    "ax[0].xaxis.set_minor_locator(mdates.MonthLocator(interval=1))  # Minor ticks for months\n",
    "ax[0].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))  # Show Year at major ticks\n",
    "ax[0].xaxis.set_minor_formatter(mdates.DateFormatter(\"%b\"))  # Show Month at minor ticks\n",
    "\n",
    "# Add axv lines to separate years\n",
    "years = rev_store_type.index.year.unique()  # Get unique years in the data\n",
    "for year in years[1:]:  # Skip first year to avoid unnecessary line at start\n",
    "    year_start = pd.Timestamp(year=year, month=1, day=1)  # Start of each year\n",
    "    ax[0].axvline(x=year_start, color=\"blue\", linestyle=\"dotted\", linewidth=2)  # Dotted separator for years\n",
    "\n",
    "# Plot the Line Graph: Revenue by Store Type\n",
    "sns.lineplot(data=rev_store_type, dashes=False, ax=ax[0])\n",
    "\n",
    "# Area Graph\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "# Ensure Abbreviated Months are Shown on plot\n",
    "ax[1].xaxis.set_major_locator(mdates.YearLocator())  # Show major tick marks for years\n",
    "ax[1].xaxis.set_minor_locator(mdates.MonthLocator(interval=1))  # Minor ticks for months\n",
    "ax[1].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))  # Show Year at major ticks\n",
    "ax[1].xaxis.set_minor_formatter(mdates.DateFormatter(\"%b\"))  # Show Month at minor ticks\n",
    "\n",
    "# Add axv lines to separate years\n",
    "years = rev_store_type.index.year.unique()  # Get unique years in the data\n",
    "for year in years[1:]:  # Skip first year to avoid unnecessary line at start\n",
    "    year_start = pd.Timestamp(year=year, month=1, day=1)  # Start of each year\n",
    "    ax[1].axvline(x=year_start, color=\"blue\", linestyle=\"dotted\", linewidth=2)  # Dotted separator for years\n",
    "\n",
    "# Handle Missing Values (Fill NaN with 0) or stackplot will fail\n",
    "rev_store_type = rev_store_type.fillna(0)\n",
    "\n",
    "# Plot the Area Graph: Revenue by Store Type\n",
    "ax[1].stackplot(\n",
    "    rev_store_type.index,  # X-axis: Order Date\n",
    "    rev_store_type[\"Online\"],  # Y1: Online Stores\n",
    "    rev_store_type[\"Physical\"],  # Y2: Physical Stores\n",
    "    labels=[\"Online Stores\", \"Physical Stores\"],  # Legend labels\n",
    "    colors=[\"blue\", \"red\"],  # Colors for Online & Physical\n",
    "    alpha=0.5  # Transparency to see overlapping areas\n",
    ")\n",
    "\n",
    "# Manually Create the Correct Legend (Ignoring axvline) as only axv line is shown as a symbol for online and physical\n",
    "legend_patches = [\n",
    "    mpatches.Patch(color=\"blue\", alpha=0.5, label=\"Online Stores\"),\n",
    "    mpatches.Patch(color=\"red\", alpha=0.5, label=\"Physical Stores\")\n",
    "]\n",
    "ax[1].legend(handles=legend_patches, loc=\"upper left\", fontsize=14)  # Increase legend size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.1.2. Online VS Physical Revenue (PLOTLY CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate the Data Using Pivot Table\n",
    "rev_store_type = sales_merged.pivot_table(index=\"Order Date\", columns=\"Store Type\", values=\"Revenue\", aggfunc=\"mean\")\n",
    "\n",
    "# Get Monthly level data from order dates for plotting\n",
    "rev_store_type = rev_store_type.resample(\"ME\").mean().fillna(0)  # Handle NaN values\n",
    "\n",
    "# Compute Cumulative Sum for Stacked Effect\n",
    "rev_store_type[\"Physical Cumulative\"] = rev_store_type[\"Physical\"]  \n",
    "rev_store_type[\"Online Cumulative\"] = rev_store_type[\"Online\"] + rev_store_type[\"Physical\"]  \n",
    "\n",
    "# Extract Unique Years for Vertical Lines\n",
    "years = rev_store_type.index.year.unique()\n",
    "\n",
    "# Use the \"Greens\" color palette\n",
    "greens_palette = px.colors.sequential.Greens  \n",
    "colors = {\"Online\": greens_palette[3], \"Physical\": greens_palette[6]}  # Light green for Online, Dark green for Physical\n",
    "\n",
    "# Create Subplots (2 Rows)\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=[\n",
    "    \"Average Revenue by Store Type\",\n",
    "    \"Average Revenue Distribution by Store Type\"\n",
    "])\n",
    "\n",
    "# Add Line Graph to Row 1\n",
    "for store_type in [\"Online\", \"Physical\"]:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=rev_store_type.index, \n",
    "        y=rev_store_type[store_type], \n",
    "        mode=\"lines\",\n",
    "        name=f\"{store_type} Revenue\",  \n",
    "        line=dict(color=colors[store_type], width=2)\n",
    "    ), row=1, col=1)\n",
    "\n",
    "# Add True Stacked Area Graph to Row 2\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=rev_store_type.index, \n",
    "    y=rev_store_type[\"Physical Cumulative\"],  # Base Layer\n",
    "    mode=\"lines\",\n",
    "    fill=\"tozeroy\",  \n",
    "    name=\"Physical Stores\",\n",
    "    line=dict(color=colors[\"Physical\"]),\n",
    "    opacity=0.6\n",
    "), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=rev_store_type.index, \n",
    "    y=rev_store_type[\"Online Cumulative\"],  # Stacked on top\n",
    "    mode=\"lines\",\n",
    "    fill=\"tonexty\",  \n",
    "    name=\"Online Stores\",\n",
    "    line=dict(color=colors[\"Online\"]),\n",
    "    opacity=0.6\n",
    "), row=2, col=1)\n",
    "\n",
    "# Add Vertical Year Separators (Replacing axvline)\n",
    "for year in years[1:]:\n",
    "    fig.add_shape(\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0=pd.Timestamp(year=year, month=1, day=1),\n",
    "            x1=pd.Timestamp(year=year, month=1, day=1),\n",
    "            y0=0, y1=1,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            line=dict(color=\"gray\", width=0.5, dash=\"dot\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Customize Layout & Appearance\n",
    "fig.update_layout(\n",
    "    title=\"Online vs. Physical Store Revenue (2016-2020)\",\n",
    "    title_font=dict(size=30),\n",
    "    xaxis=dict(title=\"\", tickformat=\"%b %Y\", tickangle=90, showgrid=False),\n",
    "    yaxis=dict(title=\"\", tickprefix=\"$\", tickformat=\",.0f\"),\n",
    "    yaxis2=dict(title=\"\", tickprefix=\"$\", tickformat=\",.0f\"),\n",
    "    legend=dict(title=\"Store Type\", font=dict(size=18)),\n",
    "    plot_bgcolor=\"white\",\n",
    "    height=600,\n",
    "    width=1400\n",
    ")\n",
    "\n",
    "# Show Interactive Plotly Graph\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.1.3. Heatmaps (Revenue and Quantity by Category for Product Brands and Color) for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color Data 2020 (Revenue and Quantities)\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Create Subplots 4x4\n",
    "fig, ax = plt.subplots(2,1, figsize=(30,13))\n",
    "\n",
    "# Filter Sales Data for 2020\n",
    "sales_20 = sales_merged[(sales_merged[\"Order Year\"] == 2020)].copy()\n",
    "\n",
    "#______________________________\n",
    "# Revenue by Category and Color\n",
    "# ______________________________\n",
    "# Aggregate the Data Using Pivot Table\n",
    "rev_cat_col = sales_20.pivot_table(index=\"Category\", columns=\"Color\", values=\"Revenue\", aggfunc=\"sum\")\n",
    "\n",
    "# Normalize revenue data to percentages (for color bar)\n",
    "rev_cat_col_percent = rev_cat_col / rev_cat_col.max().max() * 100  #  Convert data to % scale (0-100)\n",
    "\n",
    "# Keep revenue annotations in \"$\" format\n",
    "revenue_formatted = rev_cat_col.map(lambda x: f\"${x/1000:,.0f}k\")  # Display values as \"$Xk\"\n",
    "\n",
    "# Plot heatmap (Use percentage data but display $ annotations)\n",
    "sns.heatmap(rev_cat_col_percent, annot=revenue_formatted, cmap=\"Greens\", linewidths=1.5, ax=ax[0],  \n",
    "            annot_kws={\"size\": 18}, fmt=\"s\", vmin=0, vmax=100)  # `fmt=\"s\"` ensures string annotations work\n",
    "\n",
    "# Convert Color Bar to Percentage\n",
    "colorbar = ax[0].collections[0].colorbar\n",
    "ticks = colorbar.get_ticks()\n",
    "colorbar.set_ticks(ticks)\n",
    "colorbar.set_ticklabels([f\"{x:.0f}%\" for x in ticks])  # Convert color bar labels to %\n",
    "\n",
    "# Formatting___________________\n",
    "# Adjust Title\n",
    "ax[0].set_title(\"Revenue Distribution Across Categories and Colors (2020)\", fontsize=40, pad=25)\n",
    "\n",
    "# Remove x and y axis titles\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[0].set_ylabel(\"\")\n",
    "\n",
    "# Increase Y-axis and X-axis tick label size\n",
    "ax[0].tick_params(axis='x', labelsize=20)\n",
    "ax[0].tick_params(axis='y', labelsize=20)\n",
    "\n",
    "# Remove X-axis labels from the first heatmap\n",
    "ax[0].set_xticklabels([])  \n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[0].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Increase tick labels inside the color bar\n",
    "ax[0].collections[0].colorbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "# Force Extra Space between first heatmap and title of second heatmap by Adding a Blank Title Above the Second Heatmap\n",
    "ax[1].set_title(\" \", fontsize=80, pad=50, loc=\"left\")  \n",
    "\n",
    "#______________________________\n",
    "# Quantity by Category and Color\n",
    "#_______________________________\n",
    "# Aggregate the Data Using Pivot Table\n",
    "quantity_cat_col = sales_20.pivot_table(index=\"Category\", columns=\"Color\", values=\"Quantity\", aggfunc=\"sum\")\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "quantity_formatted = quantity_cat_col.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Plot Heatmap: Quantity by Category and Color\n",
    "heatmap2 = sns.heatmap(quantity_cat_col, annot=quantity_formatted, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[1], annot_kws={\"size\": 18})\n",
    "\n",
    "# Formatting_____________________\n",
    "\n",
    "# Convert Color Bar to Percentage\n",
    "colorbar = heatmap2.collections[0].colorbar\n",
    "ticks = colorbar.get_ticks()\n",
    "colorbar.set_ticks(ticks)\n",
    "colorbar.set_ticklabels([f\"{x/max(ticks) * 100:.0f}%\" for x in ticks])  # Convert to percentage\n",
    "\n",
    "# Adjust Title\n",
    "ax[1].set_title(\"Sales Volume Across Categories and Colors (2020)\", fontsize=40, pad=25)\n",
    "\n",
    "# Remove x and y axis titles\n",
    "ax[1].set_xlabel(\"\")\n",
    "ax[1].set_ylabel(\"\")\n",
    "\n",
    "# Increase Y-axis and X-axis tick label size\n",
    "ax[1].tick_params(axis='x', labelsize=20)\n",
    "ax[1].tick_params(axis='y', labelsize=20)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[1].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Increase tick labels inside the color bar\n",
    "ax[1].collections[0].colorbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Add Borders Around Each Heatmap Using Rectangle\n",
    "for a in ax:\n",
    "    rect = plt.Rectangle((0, 0), 1, 1, color=\"black\", linewidth=0.5, fill=False, transform=a.transAxes, clip_on=False)\n",
    "    a.add_patch(rect)\n",
    "\n",
    "# Show Plot______________________________\n",
    "plt.xticks(rotation=45, ha=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brand Data 2020 (Revenue and Quantity)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(2,1, figsize=(30,13))\n",
    "#_________________________________\n",
    "# Revenue by Category and Brand\n",
    "# _________________________________\n",
    "# Aggregate Data Using Pivot Table\n",
    "rev_cat_brand = sales_20.pivot_table(index=\"Category\", columns=\"Brand\", values=\"Revenue\", aggfunc=\"sum\")\n",
    "\n",
    "# Normalize revenue data to percentages (for color bar)\n",
    "rev_cat_brand_percent = rev_cat_brand / rev_cat_brand.max().max() * 100  # Convert data to % scale (0-100)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "revenue_formatted_1 = rev_cat_brand.map(lambda x: f\"${x/1000:,.0f}k\")\n",
    "\n",
    "# Plot Heatmap: Revenue by Category and Brand\n",
    "sns.heatmap(rev_cat_brand_percent, annot=revenue_formatted_1, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[0], annot_kws={\"size\": 18}, vmin=0, vmax=100)\n",
    "\n",
    "# Convert Color Bar to Percentage\n",
    "colorbar = ax[0].collections[0].colorbar\n",
    "ticks = colorbar.get_ticks()\n",
    "colorbar.set_ticks(ticks)\n",
    "colorbar.set_ticklabels([f\"{x:.0f}%\" for x in ticks])  # Convert color bar labels to %\n",
    "\n",
    "# Formatting_______________________\n",
    "# Plot Title\n",
    "ax[0].set_title(\"Revenue Distribution Across Categories & Brands (2020)\", fontsize=40, pad=25)\n",
    "\n",
    "# Remove X and Y axis titles\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[0].set_ylabel(\"\")\n",
    "\n",
    "# Increase Y-axis and X-axis tick label size\n",
    "ax[0].tick_params(axis='x', labelsize=20)\n",
    "ax[0].tick_params(axis='y', labelsize=20)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[0].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Remove X-axis labels from the first heatmap\n",
    "ax[0].set_xticklabels([])  \n",
    "\n",
    "# Increase tick labels inside the color bar\n",
    "ax[0].collections[0].colorbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "# Force Extra Space between first heatmap and title of second heatmap by Adding a Blank Title Above the Second Heatmap\n",
    "ax[1].set_title(\" \", fontsize=80, pad=50, loc=\"left\")  \n",
    "\n",
    "#__________________________________\n",
    "# Quantity by Category and Brand\n",
    "#__________________________________\n",
    "# Aggregate the Data Using Pivot Table\n",
    "quantity_cat_brand = sales_20.pivot_table(index=\"Category\", columns=\"Brand\", values=\"Quantity\", aggfunc=\"sum\")\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "quantity_formatted_1 = quantity_cat_brand.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = quantity_cat_brand.max().max()  \n",
    "\n",
    "# Plot Heatmap: Quantity by Category and Brand\n",
    "sns.heatmap(quantity_cat_brand, annot=quantity_formatted_1, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[1], annot_kws={\"size\": 18}, vmin=0, vmax=vmax)\n",
    "\n",
    "# Fix Color Bar Scale (Ensure it reaches 100%)\n",
    "colorbar = ax[1].collections[0].colorbar\n",
    "num_ticks = 6  # Adjust number of tick marks\n",
    "tick_values = np.linspace(0, vmax, num_ticks)  # Ensure it spans from 0% to 100%\n",
    "colorbar.set_ticks(tick_values)\n",
    "colorbar.set_ticklabels([f\"{(x/vmax) * 100:.0f}%\" for x in tick_values])  \n",
    "\n",
    "# Formatting________________________\n",
    "# Plot Title\n",
    "ax[1].set_title(\"Sales Volume Across Categories & Brands (2020)\", fontsize=40, pad=25)\n",
    "\n",
    "# Remove X and Y axis titles\n",
    "ax[1].set_xlabel(\"\")\n",
    "ax[1].set_ylabel(\"\")\n",
    "\n",
    "# Increase Y-axis and X-axis tick label size\n",
    "ax[1].tick_params(axis='x', labelsize=20)\n",
    "ax[1].tick_params(axis='y', labelsize=20)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[1].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Increase tick labels inside the color bar\n",
    "ax[1].collections[0].colorbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "# Add Borders Around Each Heatmap Using `Rectangle`\n",
    "for a in ax:\n",
    "    rect = plt.Rectangle((0, 0), 1, 1, color=\"black\", linewidth=0.5, fill=False, transform=a.transAxes, clip_on=False)\n",
    "    a.add_patch(rect)\n",
    "\n",
    "# Show Plot______________________________\n",
    "plt.xticks(rotation=45, ha=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.1.3 Sales By Country VS Exchange Rate Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by Country vs Exchange Rate\n",
    "fig, ax = plt.subplots(2,1, figsize=(30, 15))\n",
    "\n",
    "# Sales by Country (all years)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate Data Using Pivot Table\n",
    "revenue_by_country = sales_merged.pivot_table(index=\"Order Date\", columns=\"Store Country\", values=\"Revenue\", aggfunc=\"sum\")\n",
    "\n",
    "# Extract the months and year from order date for plotting\n",
    "revenue_by_country = revenue_by_country.resample(\"ME\").sum()\n",
    "\n",
    "# Ensure Abbreviated Months are Shown on plot\n",
    "ax[0].xaxis.set_major_locator(mdates.YearLocator())  # Show major tick marks for years\n",
    "ax[0].xaxis.set_minor_locator(mdates.MonthLocator(interval=1))  # Minor ticks for months\n",
    "ax[0].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))  # Show Year at major ticks\n",
    "ax[0].xaxis.set_minor_formatter(mdates.DateFormatter(\"%b\"))  # Show Month at minor ticks\n",
    "\n",
    "# Add axv lines to separate years\n",
    "years = revenue_by_country.index.year.unique()  # Get unique years in the data\n",
    "for year in years[1:]:  # Skip first year to avoid unnecessary line at start\n",
    "    year_start = pd.Timestamp(year=year, month=1, day=1)  # Start of each year\n",
    "    ax[0].axvline(x=year_start, color=\"blue\", linestyle=\"dotted\", linewidth=2)  # Dotted separator for years\n",
    "\n",
    "\n",
    "# Plot Graph\n",
    "sns.lineplot(data=revenue_by_country, ax=ax[0], dashes=False)\n",
    "\n",
    "# Add Title\n",
    "ax[0].set_title(\"Revenue by Country (2016–2020): Key Market Trends & Growth\")\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Exchange rate by country\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate Data Using Pivot Table\n",
    "country_exchange = sales_merged.pivot_table(index=\"Order Date\", columns=\"Store Country\", values=\"Exchange Rate\", aggfunc=\"mean\")\n",
    "\n",
    "# Extract the months and year from order date for plotting\n",
    "country_exchange = country_exchange.resample(\"ME\").mean()\n",
    "\n",
    "# Ensure Abbreviated Months are Shown on plot\n",
    "ax[1].xaxis.set_major_locator(mdates.YearLocator())  # Show major tick marks for years\n",
    "ax[1].xaxis.set_minor_locator(mdates.MonthLocator(interval=1))  # Minor ticks for months\n",
    "ax[1].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))  # Show Year at major ticks\n",
    "ax[1].xaxis.set_minor_formatter(mdates.DateFormatter(\"%b\"))  # Show Month at minor ticks\n",
    "\n",
    "# Add axv lines to separate years\n",
    "years = revenue_by_country.index.year.unique()  # Get unique years in the data\n",
    "for year in years[1:]:  # Skip first year to avoid unnecessary line at start\n",
    "    year_start = pd.Timestamp(year=year, month=1, day=1)  # Start of each year\n",
    "    ax[1].axvline(x=year_start, color=\"blue\", linestyle=\"dotted\", linewidth=2)  # Dotted separator for years\n",
    "\n",
    "# Plot Graph\n",
    "sns.lineplot(data=country_exchange, ax=ax[1], dashes=False)\n",
    "\n",
    "# Set Title\n",
    "ax[1].set_title(\"Exchange Rate Trends (2016–2020): Impact on International Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Data Using Pivot Table\n",
    "revenue_by_country = sales_merged.pivot_table(index=\"Order Date\", columns=\"Store Country\", values=\"Revenue\", aggfunc=\"sum\").resample(\"ME\").sum()\n",
    "country_exchange = sales_merged.pivot_table(index=\"Order Date\", columns=\"Store Country\", values=\"Exchange Rate\", aggfunc=\"mean\").resample(\"ME\").mean()\n",
    "\n",
    "# Get unique years\n",
    "years = revenue_by_country.index.year.unique()\n",
    "\n",
    "# Create subplots (2 rows, 1 column)\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=[\n",
    "    \"Revenue by Country (2016–2020): Key Market Trends & Growth\",\n",
    "    \"Exchange Rate Trends (2016–2020): Impact on International Sales\"\n",
    "])\n",
    "\n",
    "# Define the \"Greens\" color palette from Plotly\n",
    "color_palette = px.colors.sequential.Greens\n",
    "color_map = {country: color_palette[i % len(color_palette)] for i, country in enumerate(revenue_by_country.columns)}\n",
    "\n",
    "#  Plot Revenue by Country\n",
    "for country in revenue_by_country.columns:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=revenue_by_country.index,\n",
    "        y=revenue_by_country[country],\n",
    "        mode='lines',\n",
    "        name=country,\n",
    "        line=dict(color=color_map[country])\n",
    "    ), row=1, col=1)\n",
    "\n",
    "#  Plot Exchange Rate by Country\n",
    "for country in country_exchange.columns:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=country_exchange.index,\n",
    "        y=country_exchange[country],\n",
    "        mode='lines',\n",
    "        name=country,\n",
    "        line=dict(color=color_map[country], dash=\"dot\")\n",
    "    ), row=2, col=1)\n",
    "\n",
    "#  Add Vertical Year Lines (Gray)\n",
    "for year in years[1:]:  # Skip first year\n",
    "    year_start = pd.Timestamp(year=year, month=1, day=1)\n",
    "    fig.add_vline(x=year_start, line=dict(color=\"gray\", width=1, dash=\"dot\"), row=1, col=1)\n",
    "    fig.add_vline(x=year_start, line=dict(color=\"gray\", width=1, dash=\"dot\"), row=2, col=1)\n",
    "\n",
    "#  Update Layout\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Revenue & Exchange Rate Trends by Country (2016–2020)\", font=dict(size=30)),  \n",
    "    xaxis=dict(title=\"\", tickformat=\"%Y\", showgrid=False),  \n",
    "    xaxis2=dict(title=\"\", tickformat=\"%Y\", showgrid=False),  \n",
    "    yaxis=dict(title=\"\", tickprefix=\"$\", tickformat=\",\", showgrid=True),  \n",
    "    yaxis2=dict(title=\"\", showgrid=True),  \n",
    "    legend_title=\"Country\",\n",
    "    height=700,\n",
    "    width=1400,  \n",
    "    plot_bgcolor=\"white\",  \n",
    "    paper_bgcolor=\"white\"\n",
    ")\n",
    "\n",
    "#  Format Y-Ticks for Revenue (Show \"k\" instead of \"M\")\n",
    "tick_values = [0, 200000, 400000, 600000, 800000, 1000000]  \n",
    "tick_labels = [f\"${int(x/1000)}k\" for x in tick_values]  # Convert to \"k\" format\n",
    "\n",
    "fig.update_yaxes(\n",
    "    tickvals=tick_values,\n",
    "    ticktext=tick_labels,\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.update_yaxes(tickformat=\".2f\", row=2, col=1)  # Exchange rate as decimal\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2. Customer Segmentation and Demographics  for 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.2.1. Revenue/Quantity by Age & Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create bins for age groups (Adding Age Group Column to sales_merged)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "# Define age bins & labels\n",
    "age_bins = [0, 25, 35, 45, 55, 120]  # Ensure the max age is included\n",
    "age_labels = [\"18-25\", \"26-35\", \"36-45\", \"46-55\", \"56+\"]\n",
    "\n",
    "# Assign Age Group\n",
    "sales_20[\"Age Group\"] = pd.cut(sales_20[\"Customer Age\"], bins=age_bins, labels=age_labels, right=True, include_lowest=True)\n",
    "\n",
    "# Customer Data By Age and Gender\n",
    "fig, ax = plt.subplots(2,1, figsize=(15,4))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Revenue by Age and Gender\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate Dat Using Pivot Tables\n",
    "customer_rev = sales_20.pivot_table(index=\"Gender\", columns=\"Age Group\", values=\"Revenue\", aggfunc=\"sum\", observed=False)\n",
    "\n",
    "# Normalize revenue data to percentages (for color bar)\n",
    "customer_rev_percent = customer_rev / customer_rev.max().max() * 100  # Convert data to % scale (0-100)\n",
    "\n",
    "# Keep revenue annotations in \"$\" format\n",
    "customer_revenue_formatted = customer_rev.map(lambda x: f\"${x/1000:,.0f}k\")  # Display values as \"$Xk\"\n",
    "\n",
    "# Plot the Heatmap: Revenue by Gender and Age\n",
    "sns.heatmap(customer_rev_percent, annot=customer_revenue_formatted, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[0], annot_kws={\"size\": 12})\n",
    "\n",
    "# Formatting\n",
    "# Convert Color Bar to Percentage\n",
    "colorbar = ax[0].collections[0].colorbar\n",
    "ticks = colorbar.get_ticks()\n",
    "colorbar.set_ticks(ticks)\n",
    "colorbar.set_ticklabels([f\"{x:.0f}%\" for x in ticks])  # Convert color bar labels to %\n",
    "\n",
    "# Set title\n",
    "ax[0].set_title(\"Revenue Distribution by Age & Gender (2020): Identifying High-Value Customer Segments\", fontsize=17, pad=12)\n",
    "\n",
    "# Remove x and y labels\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[0].set_ylabel(\"\")\n",
    "\n",
    "# Increase Y-axis and X-axis tick label size\n",
    "ax[0].tick_params(axis='x', labelsize=12)\n",
    "ax[0].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[0].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Remove X-axis labels from the first heatmap\n",
    "ax[0].set_xticklabels([])  \n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Quantity by Age and Gender\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Tables\n",
    "customer_quantity = sales_20.pivot_table(index=\"Gender\", columns=\"Age Group\", values=\"Quantity\", aggfunc=\"sum\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "customer_quantity_formatted = customer_quantity.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = customer_quantity.max().max()  \n",
    "\n",
    "# Plot the Heatmap: Quantity by Age and Gender\n",
    "sns.heatmap(customer_quantity, annot=customer_quantity_formatted, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[1], annot_kws={\"size\": 12})\n",
    "\n",
    "# Formatting\n",
    "# Fix Color Bar Scale (Ensure it reaches 100%)\n",
    "colorbar = ax[1].collections[0].colorbar\n",
    "num_ticks = 6  # Adjust number of tick marks\n",
    "tick_values = np.linspace(0, vmax, num_ticks)  # Ensure it spans from 0% to 100%\n",
    "colorbar.set_ticks(tick_values)\n",
    "colorbar.set_ticklabels([f\"{(x/vmax) * 100:.0f}%\" for x in tick_values])  \n",
    "\n",
    "\n",
    "# Set title\n",
    "ax[1].set_title(\"Purchase Volume Trends (2020): How Age & Gender Influence Buying Behavior\", fontsize=17, pad=12)\n",
    "\n",
    "# Remove x and y labels\n",
    "ax[1].set_xlabel(\"\")\n",
    "ax[1].set_ylabel(\"\")\n",
    "\n",
    "# Increase Y-axis and X-axis tick label size\n",
    "ax[1].tick_params(axis='x', labelsize=12)\n",
    "ax[1].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[1].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Force Extra Space between first heatmap and title of second heatmap by Adding a Blank Title Above the Second Heatmap\n",
    "ax[1].set_title(\" \", fontsize=40, pad=15, loc=\"left\")  \n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Add Borders Around Each Heatmap Using Rectangle\n",
    "for a in ax:\n",
    "    rect = plt.Rectangle((0, 0), 1, 1, color=\"black\", linewidth=0.5, fill=False, transform=a.transAxes, clip_on=False)\n",
    "    a.add_patch(rect)\n",
    "\n",
    "# Show Plot______________________________\n",
    "plt.tight_layout()\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.2.2. Category by Age and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Data By Age and Gender\n",
    "fig, ax = plt.subplots(3,2, figsize=(30,13), gridspec_kw={\"width_ratios\": [1, 4]})\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Customer Demographics & Buying Patterns (2020): Revenue, Purchase Volume, and Customer Distribution by Age & Gender\", \n",
    "    fontsize=35, y=1.02  # Adjust `y` to position above subplots\n",
    ")\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Revenue by Product Category and Gender\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate Dat Using Pivot Tables\n",
    "customer_cat_gender = sales_20.pivot_table(index=\"Category\", columns=\"Gender\", values=\"Revenue\", aggfunc=\"sum\", observed=False)\n",
    "\n",
    "# Normalize revenue data to percentages (for color bar)\n",
    "customer_cat_gender_percent = customer_cat_gender / customer_cat_gender.max().max() * 100  #  Convert data to % scale (0-100)\n",
    "\n",
    "# Keep revenue annotations in \"$\" format\n",
    "customer_cat_gender_formatted = customer_cat_gender.map(lambda x: f\"${x/1000:,.0f}k\")  #  Display values as \"$Xk\"\n",
    "\n",
    "\n",
    "# Plot the Heatmap: Revenue by Category and Gender\n",
    "sns.heatmap(customer_cat_gender_percent, annot=customer_cat_gender_formatted, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[0,0], cbar=False, annot_kws={\"size\":18})\n",
    "\n",
    "# Formatting\n",
    "# Remove x and y label\n",
    "ax[0,0].set_xlabel(\"\")\n",
    "ax[0,0].set_ylabel(\"Revenue\", fontsize=20, color=\"#004d00\", labelpad=15)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[0,0].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Remove X-axis labels from the first heatmap\n",
    "ax[0,0].set_xticklabels([])    \n",
    "\n",
    "# Set Title\n",
    "ax[0,0].set_title(\"By Gender\", fontsize=20, color=\"#004d00\", pad=15)\n",
    "\n",
    "# Increase Y-axis tick label size\n",
    "ax[0,0].tick_params(axis='y', labelsize=20)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Revenue by Product Category and Age\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate Dat Using Pivot Tables\n",
    "customer_cat_age = sales_20.pivot_table(index=\"Category\", columns=\"Age Group\", values=\"Revenue\", aggfunc=\"sum\", observed=False)\n",
    "\n",
    "# Normalize revenue data to percentages (for color bar)\n",
    "customer_cat_age_percent = customer_cat_age / customer_cat_age.max().max() * 100  #  Convert data to % scale (0-100)\n",
    "\n",
    "# Keep revenue annotations in \"$\" format\n",
    "customer_cat_age_formatted = customer_cat_age.map(lambda x: f\"${x/1000:,.0f}k\")  #  Display values as \"$Xk\"\n",
    "\n",
    "# Plot the Heatmap: Revenue by Category and Age\n",
    "sns.heatmap(customer_cat_age_percent, annot=customer_cat_age_formatted, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[0,1], annot_kws={\"size\":18} )\n",
    "\n",
    "# Formatting \n",
    "# Convert Color Bar to Percentage\n",
    "colorbar = ax[0,1].collections[0].colorbar\n",
    "ticks = colorbar.get_ticks()\n",
    "colorbar.set_ticks(ticks)\n",
    "colorbar.set_ticklabels([f\"{x:.0f}%\" for x in ticks])  #  Convert color bar labels to %\n",
    "\n",
    "# Set Colorbar Tick Label Size\n",
    "colorbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "# Remove x and y label\n",
    "ax[0,1].set_xlabel(\"\")\n",
    "ax[0,1].set_ylabel(\"\")\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[0,1].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Remove X-axis labels from the first heatmap\n",
    "ax[0,1].set_xticklabels([])  \n",
    "\n",
    "# Remove y-axis labels from the first heatmap\n",
    "ax[0,1].set_yticklabels([])  \n",
    "\n",
    "# Set Title\n",
    "ax[0,1].set_title(\"By Age Group\", fontsize=20, color=\"#004d00\", pad=15)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Quantity by Product Category and Gender\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Tables\n",
    "customer_quantity_gender = sales_20.pivot_table(index=\"Category\", columns=\"Gender\", values=\"Quantity\", aggfunc=\"sum\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "customer_quantity_gender_formatted = customer_quantity_gender.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = customer_quantity_gender.max().max()  \n",
    "\n",
    "# Plot the Heatmap: Quantity by Category and Gender\n",
    "sns.heatmap(customer_quantity_gender, annot=customer_quantity_gender_formatted,cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[1,0], cbar=False, annot_kws={\"size\":18})\n",
    "\n",
    "# Formatting\n",
    "# Remove x and y label\n",
    "ax[1,0].set_xlabel(\"\")\n",
    "ax[1,0].set_ylabel(\"Quantity\", fontsize=20, color=\"#004d00\", labelpad=15)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[1,0].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Remove X-axis labels from the first heatmap\n",
    "ax[1,0].set_xticklabels([])  \n",
    "\n",
    "# Increase Y-axis tick label size\n",
    "ax[1,0].tick_params(axis='y', labelsize=20)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Quantity by Product Category and Age \n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Tables\n",
    "customer_quantity_age = sales_20.pivot_table(index=\"Category\", columns=\"Age Group\", values=\"Quantity\", aggfunc=\"sum\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "customer_quantity_age_formatted = customer_quantity_age.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = customer_quantity_age.max().max()  \n",
    "\n",
    "# Plot the Heatmap: Quantity by Category and Age\n",
    "sns.heatmap(customer_quantity_age, annot=customer_quantity_age_formatted,cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[1,1], annot_kws={\"size\":18})\n",
    "\n",
    "# Formatting\n",
    "# Fix Color Bar Scale (Ensure it reaches 100%)\n",
    "colorbar = ax[1,1].collections[0].colorbar\n",
    "num_ticks = 6  # Adjust number of tick marks\n",
    "tick_values = np.linspace(0, vmax, num_ticks)  #  Ensure it spans from 0% to 100%\n",
    "colorbar.set_ticks(tick_values)\n",
    "colorbar.set_ticklabels([f\"{(x/vmax) * 100:.0f}%\" for x in tick_values])  \n",
    "\n",
    "# Set Colorbar Tick Label Size\n",
    "colorbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "# Remove x and y label\n",
    "ax[1,1].set_xlabel(\"\")\n",
    "ax[1,1].set_ylabel(\"\")\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[1,1].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Remove X-axis labels from the first heatmap\n",
    "ax[1,1].set_xticklabels([])  \n",
    "\n",
    "# Remove Y-axis labels from the first heatmap\n",
    "ax[1,1].set_yticklabels([])  \n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Unique Customer Count by Product Category and Gender\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Tables\n",
    "count_cat_gender = sales_20.pivot_table(index=\"Category\", columns=\"Gender\", values=\"Customer Key\", aggfunc=\"nunique\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "count_cat_gender_formatted = count_cat_gender.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = count_cat_gender.max().max()  \n",
    "\n",
    "# Plot the Heatmap: Customer Count by Category and Gender\n",
    "sns.heatmap(count_cat_gender, annot=count_cat_gender_formatted, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[2,0], cbar=False, annot_kws={\"size\":18})\n",
    "# Formatting\n",
    "# Remove x and y label\n",
    "ax[2,0].set_xlabel(\"\")\n",
    "ax[2,0].set_ylabel(\"Customer Count\", fontsize=20, color=\"#004d00\", labelpad=15)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[2,0].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Increase X and Y-axis tick label size\n",
    "ax[2,0].tick_params(axis='y', labelsize=20)\n",
    "ax[2,0].tick_params(axis='x', labelsize=20)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Unique Customer Count by Product Category and Age \n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Tables\n",
    "count_cat_age = sales_20.pivot_table(index=\"Category\", columns=\"Age Group\", values=\"Customer Key\", aggfunc=\"nunique\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "count_cat_age_formatted = count_cat_age.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = count_cat_age.max().max()  \n",
    "\n",
    "# Plot the Heatmap: Customer Count by Category and Gender\n",
    "sns.heatmap(count_cat_age, annot=count_cat_age_formatted, cmap=\"Greens\", fmt=\"s\", linewidths=1.5, ax=ax[2,1], annot_kws={\"size\":18} )\n",
    "\n",
    "# Formatting\n",
    "# Fix Color Bar Scale (Ensure it reaches 100%)\n",
    "colorbar = ax[2,1].collections[0].colorbar\n",
    "num_ticks = 6  # Adjust number of tick marks\n",
    "tick_values = np.linspace(0, vmax, num_ticks)  #  Ensure it spans from 0% to 100%\n",
    "colorbar.set_ticks(tick_values)\n",
    "colorbar.set_ticklabels([f\"{(x/vmax) * 100:.0f}%\" for x in tick_values])  \n",
    "\n",
    "# Set Colorbar Tick Label Size\n",
    "colorbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "# Remove x and y label\n",
    "ax[2,1].set_xlabel(\"\")\n",
    "ax[2,1].set_ylabel(\"\")\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[2,1].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Remove X-axis labels from the first heatmap\n",
    "ax[2,1].set_yticklabels([]) \n",
    "\n",
    "# Increase x-axis tick label size\n",
    "ax[2,1].tick_params(axis='x', labelsize=20)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "# Add Borders Around Each Heatmap Using `Rectangle`\n",
    "# Iterate through each individual subplot\n",
    "for a in ax.flatten():  \n",
    "    rect = plt.Rectangle((0, 0), 1, 1, color=\"black\", linewidth=0.5, fill=False, transform=a.transAxes, clip_on=False)\n",
    "    a.add_patch(rect)\n",
    "    \n",
    "# Show Plot______________________________\n",
    "plt.tight_layout()\n",
    "plt.show()   \n",
    "# When intepreting these age groups, consult onedrive for the marketing strategies by age group word doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Total Revenue and Customer Count for each Country 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Total Revenue & Customer Count for Each Country\n",
    "total_revenue_per_country = sales_20.groupby(\"Store Country\")[\"Revenue\"].sum().reset_index()\n",
    "total_revenue_per_country.rename(columns={\"Revenue\": \"Total Revenue\"}, inplace=True)\n",
    "\n",
    "total_customers_per_country = sales_20.groupby(\"Store Country\")[\"Customer Key\"].nunique().reset_index()\n",
    "total_customers_per_country.rename(columns={\"Customer Key\": \"Total Customers\"}, inplace=True)\n",
    "\n",
    "# Aggregate Square Meters per Country (Summing Store Areas)\n",
    "store_area_per_country = sales_20.groupby(\"Store Country\")[\"Square Meters\"].sum().reset_index()\n",
    "\n",
    "# Aggregate Total Stores per Country (Unique Store Keys)\n",
    "total_stores_per_country = sales_20.groupby(\"Store Country\")[\"Store Key\"].nunique().reset_index()\n",
    "total_stores_per_country.rename(columns={\"Store Key\": \"Total Stores\"}, inplace=True)\n",
    "\n",
    "# Merge All Data into a Single DataFrame for Consistency\n",
    "bar_data = (\n",
    "    total_revenue_per_country\n",
    "    .merge(total_customers_per_country, on=\"Store Country\")\n",
    "    .merge(store_area_per_country, on=\"Store Country\")\n",
    "    .merge(total_stores_per_country, on=\"Store Country\")\n",
    ")\n",
    "\n",
    "# Replace zero-area stores with NaN for calculations (Fixes Pandas FutureWarning)\n",
    "bar_data[\"Square Meters\"] = bar_data[\"Square Meters\"].replace(0, float(\"nan\"))\n",
    "\n",
    "# Convert Square Meters to Thousands (K Format)\n",
    "bar_data[\"Square Meters (K)\"] = bar_data[\"Square Meters\"] / 1_000\n",
    "\n",
    "# Calculate Revenue and Customer Count per Square Meter\n",
    "bar_data[\"Revenue per m²\"] = bar_data[\"Total Revenue\"] / bar_data[\"Square Meters\"]\n",
    "bar_data[\"Customers per m²\"] = bar_data[\"Total Customers\"] / bar_data[\"Square Meters\"]\n",
    "\n",
    "# Sort Data Independently for Each Graph\n",
    "bar_data_sorted_revenue = bar_data.sort_values(by=\"Total Revenue\", ascending=False)\n",
    "bar_data_sorted_customers = bar_data_sorted_revenue.copy()\n",
    "bar_data_sorted_m2 = bar_data.sort_values(by=\"Revenue per m²\", ascending=False)\n",
    "bar_data_sorted_customers_m2 = bar_data_sorted_m2.copy()\n",
    "bar_data_sorted_square_meters = bar_data.sort_values(by=\"Square Meters\", ascending=False)\n",
    "bar_data_sorted_stores = bar_data.sort_values(by=\"Total Stores\", ascending=False)\n",
    "\n",
    "# FIX: Replace NaNs with 0 to Remove `posx and posy should be finite values` Warning\n",
    "bar_data_sorted_m2 = bar_data_sorted_m2.fillna(0)\n",
    "bar_data_sorted_customers_m2 = bar_data_sorted_customers_m2.fillna(0)\n",
    "bar_data_sorted_square_meters = bar_data_sorted_square_meters.fillna(0)\n",
    "\n",
    "# Convert Revenue to Thousands (K Format)\n",
    "bar_data_sorted_revenue[\"Total Revenue (K)\"] = bar_data_sorted_revenue[\"Total Revenue\"] / 1_000\n",
    "\n",
    "# Set Figure Size & Expand Layout for 6 Graphs (3 Rows × 2 Columns)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 10), sharey=False)\n",
    "\n",
    "# Add Business-Relevant Suptitle\n",
    "fig.suptitle(\n",
    "    \"Market Performance Analysis: Revenue, Customers, Store Area & Store Count by Country (2020)\", \n",
    "    fontsize=16, fontweight=\"bold\", y=1.02\n",
    ")\n",
    "\n",
    "# Plot Graphs\n",
    "graph_settings = [\n",
    "    (bar_data_sorted_revenue, \"Total Revenue (K)\", \"Total Revenue by Country\", axes[0, 0], \"${:,.0f}K\"),\n",
    "    (bar_data_sorted_customers, \"Total Customers\", \"Total Customers by Country (Ordered by Revenue)\", axes[0, 1], \"{:,.0f}\"),\n",
    "    (bar_data_sorted_m2, \"Revenue per m²\", \"Revenue per Square Meter by Country\", axes[1, 0], \"${:,.2f}/m²\"),\n",
    "    (bar_data_sorted_customers_m2, \"Customers per m²\", \"Customers per Square Meter by Country (Ordered by Revenue per m²)\", axes[1, 1], \"{:,.5f}/m²\"),\n",
    "    (bar_data_sorted_square_meters, \"Square Meters (K)\", \"Total Store Area by Country\", axes[2, 0], \"{:,.0f}K m²\"),  # Now in K format\n",
    "    (bar_data_sorted_stores, \"Total Stores\", \"Total Store Count by Country\", axes[2, 1], \"{:,.0f} Stores\"),\n",
    "]\n",
    "\n",
    "for data, x_col, title, ax, label_format in graph_settings:\n",
    "    sns.barplot(\n",
    "        data=data,\n",
    "        x=x_col,\n",
    "        y=\"Store Country\",\n",
    "        hue=\"Store Country\", legend=False,\n",
    "        palette=sns.color_palette(\"Greens_r\", len(data)),\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    # Restore Correct Value Formatting for Labels\n",
    "    for index, value in enumerate(data[x_col]):\n",
    "        ax.text(value, index, label_format.format(value), va='center', fontsize=10, color=\"black\")\n",
    "\n",
    "# Adjust Layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.2.3. Revenue and Unique Customer Count by Customer Age and Gender in each Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Subplots with More Space\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,  \n",
    "    subplot_titles=[\n",
    "        \"Gender-Based Revenue Trends Across Countries\", \n",
    "        \"Age Group Revenue Distribution\", \n",
    "        \"Customer Distribution by Gender\", \n",
    "        \"Customer Count by Age Group\"\n",
    "    ],\n",
    "    specs=[\n",
    "        [{\"type\": \"scattergeo\"}, {\"type\": \"scattergeo\"}],  \n",
    "        [{\"type\": \"scattergeo\"}, {\"type\": \"scattergeo\"}]  \n",
    "    ],\n",
    "    horizontal_spacing=0.0,  \n",
    "    vertical_spacing=0.08  \n",
    ")\n",
    "\n",
    "# Define Custom Shades of Green for Gender and Age Groups\n",
    "gender_colors = {\n",
    "    \"Male\": \"#ADFF2F\",  # Yellow Green \n",
    "    \"Female\": \"#006400\"  # Dark Green\n",
    "}\n",
    "\n",
    "age_group_colors = {\n",
    "    \"18-25\": \"#004d00\",  # Deep Green\n",
    "    \"26-35\": \"#008000\",  # Forest Green\n",
    "    \"36-45\": \"#32CD32\",  # Lime Green\n",
    "    \"46-55\": \"#7CFC00\",  # Light Green\n",
    "    \"56+\": \"#ADFF2F\"     # Yellow Green\n",
    "}\n",
    "\n",
    "# -------------------------------------------\n",
    "# Revenue by Country and Gender (With Legend)\n",
    "# -------------------------------------------\n",
    "rev_country_gender = sales_20.groupby([\"Store Country\", \"Gender\"], observed=False)[\"Revenue\"].sum().reset_index()\n",
    "\n",
    "map1 = px.scatter_geo(\n",
    "    rev_country_gender,\n",
    "    locations=\"Store Country\",  \n",
    "    locationmode=\"country names\",\n",
    "    size=\"Revenue\",  \n",
    "    color=\"Gender\",  \n",
    "    hover_name=\"Store Country\",\n",
    "    opacity=0.85,  \n",
    "    color_discrete_map=gender_colors\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Revenue by Country and Age Group (With Legend)\n",
    "# -------------------------------------------\n",
    "rev_country_age = sales_20.groupby([\"Store Country\", \"Age Group\"], observed=False)[\"Revenue\"].sum().reset_index()\n",
    "\n",
    "map2 = px.scatter_geo(\n",
    "    rev_country_age,\n",
    "    locations=\"Store Country\",\n",
    "    locationmode=\"country names\",\n",
    "    size=\"Revenue\",\n",
    "    color=\"Age Group\",\n",
    "    hover_name=\"Store Country\",\n",
    "    opacity=0.85,  \n",
    "    color_discrete_map=age_group_colors\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Unique Customer Count by Country and Gender ( No Legend)\n",
    "# -------------------------------------------\n",
    "count_country_gender = sales_20.groupby([\"Store Country\", \"Gender\"], observed=False)[\"Customer Key\"].nunique().reset_index()\n",
    "\n",
    "map3 = px.scatter_geo(\n",
    "    count_country_gender,\n",
    "    locations=\"Store Country\",\n",
    "    locationmode=\"country names\",\n",
    "    size=\"Customer Key\",\n",
    "    color=\"Gender\",\n",
    "    hover_name=\"Store Country\",\n",
    "    opacity=0.85,  \n",
    "    color_discrete_map=gender_colors\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Unique Customer Count by Country and Age Group ( No Legend)\n",
    "# -------------------------------------------\n",
    "count_country_age = sales_20.groupby([\"Store Country\", \"Age Group\"], observed=False)[\"Customer Key\"].nunique().reset_index()\n",
    "\n",
    "map4 = px.scatter_geo(\n",
    "    count_country_age,\n",
    "    locations=\"Store Country\",\n",
    "    locationmode=\"country names\",\n",
    "    size=\"Customer Key\",\n",
    "    color=\"Age Group\",\n",
    "    hover_name=\"Store Country\",\n",
    "    opacity=0.85,  \n",
    "    color_discrete_map=age_group_colors\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Add Each Map to the Subplot\n",
    "# -------------------------------------------\n",
    "for trace in map1.data:\n",
    "    fig.add_trace(trace, row=1, col=1)  \n",
    "for trace in map2.data:\n",
    "    fig.add_trace(trace, row=1, col=2)  \n",
    "for trace in map3.data:\n",
    "    fig.add_trace(trace, row=2, col=1)  \n",
    "for trace in map4.data:\n",
    "    fig.add_trace(trace, row=2, col=2)  \n",
    "\n",
    "# Update Layout: Title, Size, and Legend\n",
    "fig.update_layout(\n",
    "    title_text=\"Sales Analysis - 4 Bubble Maps\",   \n",
    "    height=700,  # Increase figure height\n",
    "    width=1400   # Increase figure width\n",
    ")\n",
    "\n",
    "# Properly Hide Legends for Certain Maps\n",
    "fig.update_traces(showlegend=True, selector=dict(name=\"Male\"))  # Keep Gender legend\n",
    "fig.update_traces(showlegend=True, selector=dict(name=\"Female\"))  # Keep Gender legend\n",
    "fig.update_traces(showlegend=True, selector=dict(name=\"18-25\"))  # Keep Age legend\n",
    "fig.update_traces(showlegend=True, selector=dict(name=\"26-35\"))  \n",
    "fig.update_traces(showlegend=True, selector=dict(name=\"36-45\"))  \n",
    "fig.update_traces(showlegend=True, selector=dict(name=\"46-55\"))  \n",
    "fig.update_traces(showlegend=True, selector=dict(name=\"56+\"))  \n",
    "\n",
    "# Hide legends from maps 3 and 4\n",
    "fig.update_traces(showlegend=False, row=2, col=1)  # Customer Count by Gender\n",
    "fig.update_traces(showlegend=False, row=2, col=2)  # Customer Count by Age Group\n",
    "\n",
    "# Show Final Plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.2.4. Repeat VS One-Time Buyers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data using group by and create a buyer type column \n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "# One Time Buyer:       Buys Once in the year 2019\n",
    "# Light Repeat Buyer:   Buys 2 times in the year 2019\n",
    "# Frequent Buyer:       Buys between 3-4 times in the year 2019\n",
    "# Loyal Customer:       Buys 5-6 times in the year 2019\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# Percentage Customers per Buyer Category\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# Filter sales_merged for 2019 data\n",
    "sales_19 = sales_merged[sales_merged[\"Order Year\"] == 2019]\n",
    "\n",
    "# Count the number of purchases per customer\n",
    "customer_orders_19 = sales_19.groupby(\"Customer Key\")[\"Order Number\"].nunique().reset_index()\n",
    "\n",
    "# Define purchase frequency categories\n",
    "def classify_buyer(purchases):\n",
    "    if purchases == 1:\n",
    "        return \"One-Time Buyer\"\n",
    "    elif purchases == 2:\n",
    "        return \"Light Repeat Buyer\"\n",
    "    elif purchases <= 4:\n",
    "        return \"Frequent Buyer\"\n",
    "    else:\n",
    "        return \"Loyal Customer\"\n",
    "\n",
    "# Apply classification\n",
    "customer_orders_19[\"Buyer Category\"] = customer_orders_19[\"Order Number\"].apply(classify_buyer)\n",
    "\n",
    "# Aggregate data to obtain percentage customers per buyer category\n",
    "customer_19_buyer = customer_orders_19.groupby(\"Buyer Category\")[\"Customer Key\"].count()\n",
    "\n",
    "# Convert to percentage\n",
    "customer_19_buyer_percentage = customer_19_buyer / customer_19_buyer.sum() * 100\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "# Revenue % per Buyer Category\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Merge the buyer type column with sales 2020 to aggregate by revenue and aggregate using groupby for plotting bar graph\n",
    "sales_19_buyer = sales_19.merge(customer_orders_19, on=\"Customer Key\", how=\"left\")\n",
    "\n",
    "# Aggregate revenue by buyer category\n",
    "rev_buyer_19 = sales_19_buyer.groupby(\"Buyer Category\")[\"Revenue\"].sum()\n",
    "\n",
    "# Convert to percentage\n",
    "rev_buyer_percentage_19 = rev_buyer_19 / rev_buyer_19.sum() * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data using group by and create a buyer type column \n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "# One Time Buyer:       Buys Once in the year 2020\n",
    "# Light Repeat Buyer:   Buys 2 times in the year 2020\n",
    "# Frequent Buyer:       Buys between 3-4 times in the year 2020\n",
    "# Loyal Customer:       Buys 5-6 times in the year 2020\n",
    "# Note:                 There are no loyal customers in this data set so encourage business to increase customer purchases per year\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# Customer Order Percentage\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# Count the number of purchases per customer\n",
    "customer_orders_20 = sales_20.groupby(\"Customer Key\")[\"Order Number\"].nunique().reset_index()\n",
    "\n",
    "# Define purchase frequency categories\n",
    "def classify_buyer(purchases):\n",
    "    if purchases == 1:\n",
    "        return \"One-Time Buyer\"\n",
    "    elif purchases == 2:\n",
    "        return \"Light Repeat Buyer\"\n",
    "    elif purchases <= 4:\n",
    "        return \"Frequent Buyer\"\n",
    "    else:\n",
    "        return \"Loyal Customer\"\n",
    "\n",
    "# Apply classification\n",
    "customer_orders_20[\"Buyer Category\"] = customer_orders_20[\"Order Number\"].apply(classify_buyer)\n",
    "\n",
    "# Aggregate data to obtain percentage customers per buyer category\n",
    "customer_20_buyer = customer_orders_20.groupby(\"Buyer Category\")[\"Customer Key\"].count()\n",
    "\n",
    "# Convert to percentage\n",
    "customer_20_buyer_percentage = customer_20_buyer / customer_20_buyer.sum() * 100\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "# Revenue % per Buyer Category\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Merge the buyer type column with sales 2020 to aggregate by revenue and aggregate using groupby for plotting bar graph\n",
    "sales_20_buyer = sales_20.merge(customer_orders_20, on=\"Customer Key\", how=\"left\")\n",
    "\n",
    "# Aggregate revenue by buyer category\n",
    "rev_buyer_20 = sales_20_buyer.groupby(\"Buyer Category\")[\"Revenue\"].sum()\n",
    "\n",
    "# Convert to percentage\n",
    "rev_buyer_percentage_20 = rev_buyer_20 / rev_buyer_20.sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Revenue Tables for 2019 and 2020 to plot on one graph\n",
    "rev_buyer_merged = pd.merge(rev_buyer_percentage_19, rev_buyer_percentage_20, on=\"Buyer Category\", how=\"outer\")\n",
    "rev_buyer_merged.fillna(0, inplace=True) # this allows loyal customers to show up on the graph despite being 0 for 2020\n",
    "\n",
    "# Reset the Index\n",
    "rev_buyer_merged = rev_buyer_merged.reset_index()\n",
    "\n",
    "# Rename Revenue_x and Revenue_y to 2019 and 2020\n",
    "rev_buyer_merged = rev_buyer_merged.rename(columns={\"Revenue_x\" : \"2019\", \"Revenue_y\" : \"2020\"})\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Merge Customer Percentage Count Tables for 2019 and 2020\n",
    "customer_buyer_merged = pd.merge(customer_19_buyer_percentage, customer_20_buyer_percentage, on=\"Buyer Category\", how=\"outer\")\n",
    "\n",
    "# Reset the Index\n",
    "customer_buyer_merged = customer_buyer_merged.reset_index()\n",
    "\n",
    "# Rename Customer Key_x and Customer Key_y to 2019 and 2020\n",
    "customer_buyer_merged = customer_buyer_merged.rename(columns={\"Customer Key_x\" : \"2019\", \"Customer Key_y\" : \"2020\"})\n",
    "customer_buyer_merged.fillna(0, inplace=True) # this allows loyal customers to show up on the graph despite being 0 for 2020\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "# Convert Wide Format to Long Format\n",
    "rev_buyer_long = rev_buyer_merged.melt(id_vars=\"Buyer Category\", var_name=\"Year\", value_name=\"Percentage\")\n",
    "customer_buyer_long = customer_buyer_merged.melt(id_vars=\"Buyer Category\", var_name=\"Year\", value_name=\"Percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2019 vs 2020 Buyer Category Percentages Using Merged Tables\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30,10))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Revenue Percentage by Buyer Category\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "sns.barplot(data=rev_buyer_long, x=\"Buyer Category\", y=\"Percentage\", hue=\"Year\", palette=[\"skyblue\", \"orange\"], ax=ax[0])\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Percentage Customers per Buyer Category\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "sns.barplot(data=customer_buyer_long, x=\"Buyer Category\", y=\"Percentage\", hue=\"Year\", palette=[\"lightcoral\", \"gold\"], ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots (1 row, 2 columns)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(33, 10))\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------------\n",
    "# Revenue Percentage by Buyer Category (Sorted in Descending Order)\n",
    "# -------------------------------------------------------------------------------------------------------------------------------\n",
    "data1 = rev_buyer_long.sort_values(by=\"Percentage\", ascending=False)\n",
    "\n",
    "sns.barplot(\n",
    "    data=data1, y=\"Buyer Category\", x=\"Percentage\", hue=\"Year\", palette=\"Greens\", ax=ax[0], orient=\"h\", legend=False\n",
    ")\n",
    "\n",
    "# Add percentage labels to each bar\n",
    "for container in ax[0].containers:\n",
    "    ax[0].bar_label(container, fmt=\"%.1f%%\", padding=5, fontsize=20)  # Show percentages\n",
    "\n",
    "# Formatting\n",
    "ax[0].set_title(\"Revenue Percentage by Buyer Category (2019 vs 2020)\", fontsize=34, pad=15)\n",
    "ax[0].set_xlabel(\"\")  # Remove x-axis label\n",
    "ax[0].set_ylabel(\"\", fontsize=14)\n",
    "ax[0].set_xticks([])  # Remove x-axis ticks & labels\n",
    "\n",
    "# Remove Borders\n",
    "ax[0].spines[\"right\"].set_visible(False)\n",
    "ax[0].spines[\"top\"].set_visible(False)\n",
    "ax[0].spines[\"bottom\"].set_visible(False)\n",
    "ax[0].spines[\"left\"].set_visible(False)\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[0].tick_params(axis=\"y\", length=0)\n",
    "\n",
    "# Increase Y-axis tick label size\n",
    "\n",
    "ax[0].tick_params(axis='y', labelsize=25)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------------\n",
    "# Percentage of Customers per Buyer Category (Sorted in Descending Order)\n",
    "# -------------------------------------------------------------------------------------------------------------------------------\n",
    "data2 = customer_buyer_long.sort_values(by=\"Percentage\", ascending=False)\n",
    "\n",
    "sns.barplot(\n",
    "    data=data2, y=\"Buyer Category\", x=\"Percentage\", hue=\"Year\", palette=\"Greens\", ax=ax[1], orient=\"h\"\n",
    ")\n",
    "\n",
    "# Add percentage labels to each bar\n",
    "for container in ax[1].containers:\n",
    "    ax[1].bar_label(container, fmt=\"%.1f%%\", padding=5, fontsize=20)  # Show percentages\n",
    "\n",
    "# Formatting\n",
    "ax[1].set_title(\"Percentage of Customers per Buyer Category (2019 vs 2020)\", fontsize=34, pad=15)\n",
    "ax[1].set_xlabel(\"\")  # Remove x-axis label\n",
    "ax[1].set_ylabel(\"\")  # Remove redundant y-axis label\n",
    "ax[1].set_xticks([])  # Remove x-axis ticks & labels\n",
    "ax[1].set_yticks([])  # Remove y-axis ticks & labels\n",
    "\n",
    "# Remove Borders\n",
    "ax[1].spines[\"right\"].set_visible(False)\n",
    "ax[1].spines[\"top\"].set_visible(False)\n",
    "ax[1].spines[\"bottom\"].set_visible(False)\n",
    "ax[1].spines[\"left\"].set_visible(False)\n",
    "\n",
    "# Increase Legend Size\n",
    "ax[1].legend(fontsize=30)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Subplots\n",
    "fig, ax = plt.subplots(2, 2, figsize=(30,10))\n",
    "fig.suptitle(\"Customer Segmentation (2020): Repeat vs. One-Time Buyers Across Key Demographics\", fontsize=40, y=1.02)  # Adjust y for padding\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Unique Customers by Gender\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Table\n",
    "buyer_gender = sales_20_buyer.pivot_table(index=\"Buyer Category\", columns=\"Gender\", values=\"Customer Key\", aggfunc=\"nunique\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "buyer_gender_formatted = buyer_gender.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = buyer_gender.max().max()  \n",
    "\n",
    "# Plot Heatmap: Unique Customers By Gender\n",
    "sns.heatmap(buyer_gender, annot=buyer_gender_formatted, fmt=\"s\", cmap=\"Greens\", linewidths=1.5, ax=ax[0,0], cbar=False, annot_kws={\"size\": 22})\n",
    "\n",
    "# Formatting\n",
    "# Set Title\n",
    "ax[0,0].set_title(\"Gender Trends: Do Men or Women Shop More Frequently?\", fontsize=25, pad=10)\n",
    "\n",
    "# Remove x and y labels\n",
    "ax[0,0].set_xlabel(\"\")\n",
    "ax[0,0].set_ylabel(\"\")\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[0,0].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Increase x-axis tick label size\n",
    "ax[0,0].tick_params(axis='both', labelsize=20)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Unique Customers by Age Group\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Table\n",
    "buyer_age = sales_20_buyer.pivot_table(index=\"Buyer Category\", columns=\"Age Group\", values=\"Customer Key\", aggfunc=\"nunique\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "buyer_age_formatted = buyer_age.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = buyer_age.max().max()  \n",
    "\n",
    "# Plot the Heatmap: Unique Customers by Age Group\n",
    "sns.heatmap(buyer_age, annot=buyer_age_formatted, fmt=\"s\", cmap=\"Greens\", linewidths=1.5, ax=ax[0,1], annot_kws={\"size\": 22})\n",
    "\n",
    "# Formatting\n",
    "# Set Title\n",
    "ax[0,1].set_title(\"Age & Buying Behavior: Who Are Our Most Loyal Customers?\", fontsize=25, pad=10)\n",
    "\n",
    "# Remove x and y labels\n",
    "ax[0,1].set_xlabel(\"\")\n",
    "ax[0,1].set_ylabel(\"\")\n",
    "\n",
    "# Remove y axis tick labels\n",
    "ax[0,1].set_yticks([])\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[0,1].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Add an empty title to create space above the bottom row\n",
    "ax[1, 0].set_title(\"\\n\", fontsize=20)  # Empty title adds padding\n",
    "ax[1, 1].set_title(\"\\n\", fontsize=20)  # Empty title for symmetry\n",
    "\n",
    "# Increase x-axis tick label size\n",
    "ax[0,1].tick_params(axis='both', labelsize=20)\n",
    "\n",
    "# Fix Color Bar Scale (Ensure it reaches 100%)\n",
    "colorbar = ax[0,1].collections[0].colorbar\n",
    "num_ticks = 6  # Adjust number of tick marks\n",
    "tick_values = np.linspace(0, vmax, num_ticks)  #  Ensure it spans from 0% to 100%\n",
    "colorbar.set_ticks(tick_values)\n",
    "colorbar.set_ticklabels([f\"{(x/vmax) * 100:.0f}%\" for x in tick_values])  \n",
    "\n",
    " # Increase font size of colorbar\n",
    "ax[0,1].collections[0].colorbar.ax.tick_params(labelsize=20) \n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Unique Customers per Product Category\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Table\n",
    "buyer_cat = sales_20_buyer.pivot_table(index=\"Buyer Category\", columns=\"Category\", values=\"Customer Key\", aggfunc=\"nunique\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "buyer_cat_formatted = buyer_cat.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = buyer_cat.max().max()  \n",
    "\n",
    "# Plot Heatmap: Unique Customers per Product Category\n",
    "sns.heatmap(buyer_cat, annot=buyer_cat_formatted, fmt=\"s\", cmap=\"Greens\", linewidths=1.5, ax=ax[1,0], cbar=False, annot_kws={\"size\": 22})\n",
    "\n",
    "# Formatting\n",
    "# Set Title\n",
    "ax[1,0].set_title(\"Product Preferences: What Categories Drive Customer Loyalty?\", fontsize=25, pad=10, loc=\"left\"\n",
    "\"\")\n",
    "\n",
    "# Remove x and y labels\n",
    "ax[1,0].set_xlabel(\"\")\n",
    "ax[1,0].set_ylabel(\"\")\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[1,0].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Increase x-axis tick label size\n",
    "ax[1,0].tick_params(axis='both', labelsize=20)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "# Unique Customers per Country\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "# Aggregate the Data Using Pivot Table\n",
    "buyer_country = sales_20_buyer.pivot_table(index=\"Buyer Category\", columns=\"Store Country\", values=\"Customer Key\", aggfunc=\"nunique\", observed=False)\n",
    "\n",
    "# Format the cell values (annotations)\n",
    "buyer_country_formatted = buyer_country.map(lambda x: f\"{x: .0f}\")  \n",
    "\n",
    "# Set the maximum quantity for the color bar percentage\n",
    "vmax = buyer_country.max().max()  \n",
    "\n",
    "# Plot Heatmap: Unique Customers By Country\n",
    "sns.heatmap(buyer_country, annot=buyer_country_formatted, fmt=\"s\", cmap=\"Greens\", linewidths=1.5, ax=ax[1,1], annot_kws={\"size\": 22})\n",
    "\n",
    "# Formatting\n",
    "# Set Title\n",
    "ax[1,1].set_title(\"Geographic Insights: Where Do Our Most Loyal Customers Live?\", fontsize=25, pad=10, loc=\"left\")\n",
    "\n",
    "# Remove x and y labels\n",
    "ax[1,1].set_xlabel(\"\")\n",
    "ax[1,1].set_ylabel(\"\")\n",
    "\n",
    "# Remove y axis tick labels\n",
    "ax[1,1].set_yticks([])\n",
    "\n",
    "# Remove the tick marks from the x and y axis\n",
    "ax[1,1].tick_params(axis=\"both\", length=0)\n",
    "\n",
    "# Increase x-axis tick label size\n",
    "ax[1,1].tick_params(axis='both', labelsize=20)\n",
    "\n",
    "# Fix Color Bar Scale (Ensure it reaches 100%)\n",
    "colorbar = ax[1,1].collections[0].colorbar\n",
    "num_ticks = 6  # Adjust number of tick marks\n",
    "tick_values = np.linspace(0, vmax, num_ticks)  #  Ensure it spans from 0% to 100%\n",
    "colorbar.set_ticks(tick_values)\n",
    "colorbar.set_ticklabels([f\"{(x/vmax) * 100:.0f}%\" for x in tick_values])  \n",
    "\n",
    " # Increase font size of colorbar\n",
    "ax[1,1].collections[0].colorbar.ax.tick_params(labelsize=20) \n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Add Borders Around Each Heatmap Using `Rectangle`\n",
    "for a in ax.flat:\n",
    "    rect = plt.Rectangle((0, 0), 1, 1, color=\"black\", linewidth=1, fill=False, transform=a.transAxes, clip_on=False)\n",
    "    a.add_patch(rect)\n",
    "\n",
    "# Loop through last row and rotate x tick labels\n",
    "for a in ax[1].flat: \n",
    "    a.set_xticklabels(a.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 50 products by total quantity sold\n",
    "top_products = sales_20.groupby(\"Product Key\")[\"Quantity\"].sum().nlargest(50).index\n",
    "\n",
    "# Filter dataset for only the top products\n",
    "filtered_df = sales_20[sales_20[\"Product Key\"].isin(top_products)]\n",
    "\n",
    "# Create a pivot table for product bundling analysis\n",
    "basket = filtered_df.pivot_table(index=\"Order Number\", columns=\"Product Key\", \n",
    "                                 values=\"Quantity\", aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "# Compute co-purchase matrix\n",
    "co_purchase_matrix = basket.T.dot(basket)\n",
    "\n",
    "# Set diagonal to zero (self-purchase counts aren't relevant)\n",
    "np.fill_diagonal(co_purchase_matrix.values, 0)\n",
    "\n",
    "# Plot heatmap with Greens color palette\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(co_purchase_matrix, cmap=\"Greens\", linewidths=0.5)\n",
    "plt.title(\"Product Bundling Heatmap (Top 50 Products for 2020)\", fontsize=18, pad=10)\n",
    "plt.xlabel(\"Product\")\n",
    "plt.ylabel(\"Product\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datanerd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
